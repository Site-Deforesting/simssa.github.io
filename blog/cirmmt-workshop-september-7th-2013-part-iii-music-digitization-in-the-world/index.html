<!DOCTYPE html>
<html lang="en-us">
  <head>
    <link href="http://gmpg.org/xfn/11" rel="profile">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <!-- Enable responsiveness on mobile devices-->
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
    <meta name="theme-color" content="#3E3F3A">
    <!-- Windows Phone -->
    <meta name="msapplication-navbutton-color" content="#3E3F3A">
    <!-- iOS Safari -->
    <meta name="apple-mobile-web-app-status-bar-style" content="#3E3F3A">
    <title>      CIRMMT Workshop, September 7th, 2013, Part III: Music Digitization in the World &middot; SIMSSA  </title>
    <link rel="shortcut icon" type="image/ico" href="../../assets/favicon.png">
    <!-- CSS -->
    <link rel="stylesheet" href="../../assets/css/main.css" />
  </head>
  <body id ="Site" class='layout-reverse theme-base-sm sidebar-overlay'>
    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
      content to avoid any CSS collisions with our real content. -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <div class="navbar navbar-expand-sm navbar-default navbar-fixed-top" role="navigation">
      <div class="container" id="nav-container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="../../">SIMSSA</a>
        </div>
        <div class="collapse navbar-collapse">
          <ul class="navbar-nav nav mr-auto">
            <li><a href="../../about">About</a></li>
            <li><a href="../../people">Participants</a></li>
            <li class="dropdown">
              <a class="dropdown-toggle" role="button" data-toggle="dropdown" href="#">Activities<span class="caret"></span></a>
              <ul class="dropdown-menu" role="menu">
                <li><a href='../../activities/corpora-and-datasets/' target='_top' >Datasets and Corpora</a></li>
                <li><a href='../../activities/impact/' target='_top' >Our impact</a></li>
                <li><a href='../../activities/media/' target='_top' >Media</a></li>
                <li><a href='../../activities/presentations/' target='_top' >Presentations</a></li>
                <li><a href='../../activities/publications/' target='_top' >Publications</a></li>
                <li><a href='../../activities/workshops/' target='_top' >Workshops</a></li>
              </ul>
            </li>
            <li class="dropdown">
              <a class="dropdown-toggle" role="button" data-toggle="dropdown" href="#">Projects and links<span class="caret"></span></a>
              <ul class="dropdown-menu" role="menu">
                <li><a href='http://cantus.simssa.ca/' target='_top' >Cantus Ultimus</a></li>
                <li><a href='' target='_top' >ELVIS Project</a></li>
                <li><a href='http://jmir.sourceforge.net/index_jSymbolic.html' target='_top' >jSymbolic2</a></li>
                <li><a href='http://liber.simssa.ca' target='_top' >Liber Usualis</a></li>
                <li><a href='https://github.com/DDMAL/Andrew-Hughes-Chant' target='_top' >LMLO</a></li>
                <li><a href='' target='_top' >Musiclibs</a></li>
                <li><a href='http://ddmal.teamwork.com/' target='_top' >Teamwork</a></li>
                <hr id="menu-divider">
                <li><a href="http://github.com/DDMAL" target="_blank">Github</a></li>
                <li><a href="http://twitter.com/simssaproject" target="_blank">Twitter</a></li>
              </ul>
            </li>
            <li><a href="../../blog">Blog</a></li>
            <li><a href="../../opportunities">Opportunities</a></li>
            <li><a href="../../contact">Contact us</a></li>
          </ul>
        </div>
      </div>
    </div>
    <div class="post">
      <div class="container">
        <div class="page-header" id="banner">
          <div class="row">
            <div class="col-lg-12">
            </div>
          </div>
        </div>
        <div class="row">
          <div class="col-lg-12">
            <h2>CIRMMT Workshop, September 7th, 2013, Part III: Music Digitization in the World</h2>
            <br />
            <p class="blog-post">
              Posted by Catherine Motuz on September 14, 2013
            </p>
            <br />
            <p>
            <p><strong>Laurent Pugin: Looking at printed music anthologies in the context of digitization</strong></p>
            <p>Laurent Pugin, a former McGill postdoc now working for <a href="http://www.rism-ch.org/">RISM Switzerland</a>, focused on the challenges of using OMR software on large collections of music. Using <a href="http://www.aruspix.net/">Aruspix</a>, a programme that uses machine learning and a graphical user interface (GUI) to perform OMR on early printed music, Laurent has been processing the resources of <a href="http://digirep.rhul.ac.uk/">Early Music Online</a>. This resource, the product of a JISM rapid igitization grant involving the Royal Holloway, British Library and RISM UK, incudes 324 anthologies of printed music from the sixteenth century, or around 10000 pieces. The pieces are rich in metadata but because the images are produced from microfilms, the image quaility is variable.</p>
            <p>The variable quality, along with book formats, notation types and printing methods, reduced the selection of pieces that Aruspix could process. Partbooks and choirbooks were machine-readable, but table books, with parts oriented in different directions, were not (though it would be an easy problem to solve). Lute and organ tablatures, square notations, and mixed notations were all out, while only single impression printing was processable—no engravings or woodcuts. However, even with all of these limitations, Laurent was able to process 260 books, or 80% of the collection. The set left over included 49 printers, well-distributed between Venice, Antwerp, Paris and Nuremberg, showing that it was probably a very good sample of the total set, not only of the collection, but of the 4200 prints found in <a href="http://en.wikipedia.org/wiki/R%C3%A9pertoire_International_des_Sources_Musicales#RISM_Series_A.2FI_.E2.80.93_Music_Prints">RISM A/1</a>.</p>
            <p>Aruspix was used to run OMR on one page per source, then, using the same settings as provided optimal results for the page, the whole source was processed. Aruspix acheived a recognition score of 80-100% for 3/4 of the pages, with some user interaction required to provide missing clefs and to help the computer follow parts layed out over multiple pages. The high success rate and relatively small amount of human interaction proved the concept that it is indeed possible to effectively run OMR on a large scale, validating afundamental premise of the work presently going on around the world and in the DDMAL lab.</p>
            <p><strong>Perry Roland: The current state of Music Encoding Initiative</strong></p>
            <p>One of the key elements underpinning Rodan is a sophisticated and versatile music-encoding language that allows the encoding not only of different types of music notation, but of other elements such as the position of notes on a page, simultaneous variants, and many other attributes. But MEI is not just a framework for encoding music, Perry reminded us, it is also an organization, a research community, a music notation data model and a markup language.</p>
            <p><a href="http://music-encoding.org/">MEI</a> stands for “Music Encoding Initiative,” but the acronym also has hidden meanings. “Mei” in Chinese means beautiful and well-built, while it is no accident that the meetings surrounding MEI’s development as well as new releases tend to take place in the fifth month of the year. This year the meeting took the form of a two-and-a-half day music encoding conference in Mainz, Germany, where as well as exchanging ideas about how to encode music, the MEI team obtained support for a work group, and began discussing how they might run themselves as an organization. Among the projects discussed, <a href="http://www.freischuetz-digital.de/">The Freischütz Digital project</a>, functions as a proof of concept to show off MEI’s unique ability to encode variations between different sources of a piece. Activities are planned well into 2014, but Perry stressed that the present grant that supports MEI development runs out on October 15th of this year, and they are seeking alternate ways to support themselves.</p>
            <p>Perry then brought us up to date on MEI’s capabilities, as of the May 2013 release. He reminded us that, far from being a fixed format—or even a file format—MEI is simply a framework that allows for detailed music encoding. It functions on the principle of ODD—One Document Does-it-all—meaning that a single file contains not only the musical data of a piece, but functionality rules and even documentation. Of course MEI has progressed beyong the theory of being just a framework: out of the box, the newest version comes with 24 modules or customizations, giving the user the ability to encode metadata, neume, mensural and common western music notation, graphical position data, library information, the critical apparatus of a piece, editorial notes (composer additions etc.), and can even encode the contextual stylistic rules of a given piece.</p>
            <p>At this point, Julie asked if anyone has been working on encoding text and music together into a single document, to which Perry replied that it is indeed being worked on: <a href="http://www.tei-c.org/">TEI</a> (Text Encoding Initiative) has a customization to embed MEI, and the <a href="http://duchemin.haverford.edu/">Digital Duchemin Project</a> employs both TEI and MEI together.</p>
            <p>Perry ended his talk by giving a glimpse into future developments, including genetic editions (which encode not only what is on the page, but also try to reconstruct process), more translators and tools, and tools to not only encode but to compare variants in pieces.</p>
            <p><strong>Mitchell Brodsky: New York Philharmonic Digital Archives</strong></p>
            <p>Mitchell Brodsky came to us from the archives of the third oldest orchestra in the world, the New York Philharmonic. Founded in 1842, it is also the oldest orchestra in the USA, it was formed as a collective with a taste for posterity, beginning its first season with Beethoven’s monumental 5th, and self-consciously collecting every score, part, programme, photograph, recording, business record and press clipping since. All this adds up to around 7000 hours of audio and video, and millions of pages of documents. Where does SIMSSA come in? 1.3 million pages of scores and parts, dating from 1943 to 1970—the time when Leonard Bernstein was working with the orchestra—are now available for perusal on <a href="http://archives.nyphil.org/">archives.nyphil.org</a>.</p>
            <p>The interesting thing about these scores is that the markings on them haven’t been erased. Scores have been marked up by conductors, and in some cases, as when Mahler came to conduct the orchestra, by composers; parts have been marked up with playing notes, and sometimes a single score will carry traces of multiple interpretations—we were shown a score of Mahler’s 1st symphony marked up by Mahler, Walter and Bernstein. The NY Phil archives have three goals when it comes to these scores: firstly, to recognize markings; secondly to recognize authors; and thirdly to try to figure out how a particular set of markings translate into an interpretation and what it would have sounded like. Sometimes these jobs are easy, but other times symbols that mean one thing to one conductor in one situation (like a triangle to show a measure in 3) mean something different to another conductor or the same one in another circumstance (cue the triangle player!).</p>
            <p>While RODAN endeavours to marry OMR, MEI, DIVA and other components, its modular nature means that it could be expanded to suit this fascinating digitization project. Not only can it encode the music on these millions of pages, but also the texts and symbols (printed and scrawled), incorporate handwriting recognition software to try to determine who is who, and making some sense of how composers related to scores in the middle of the twentieth century.</p>
            </p>
          </div>
        </div>
        <br />
        <hr />
        <br />
        <div class="related">
          <h2>Related Posts</h2>
          <ul class="related-posts">
            <li>
              <h3>
                <a href="../../blog/MMLworkshop/">
                  Music and Machine Learning Workshop
                </a>
              </h3>
            </li>
            <li>
              <h3>
                <a href="../../blog/ismir2019/">
                  ISMIR 2019: Delft
                </a>
              </h3>
            </li>
            <li>
              <h3>
                <a href="../../blog/simssa-xix/">
                  SIMSSA XIX: Introducing DACT and MML16
                </a>
              </h3>
            </li>
          </ul>
          <br /><br /><br>
        </div>
      </div>
    </div>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
    <script type="text/javascript" src="../../js/bootstrap.min.js"></script>
  </body>
</html>
<!DOCTYPE html>
<html lang="en-us">
  <head>
    <link href="http://gmpg.org/xfn/11" rel="profile">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <!-- Enable responsiveness on mobile devices-->
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
    <meta name="theme-color" content="#3E3F3A">
    <!-- Windows Phone -->
    <meta name="msapplication-navbutton-color" content="#3E3F3A">
    <!-- iOS Safari -->
    <meta name="apple-mobile-web-app-status-bar-style" content="#3E3F3A">
    <title>      Blog &middot; SIMSSA  </title>
    <link rel="shortcut icon" type="image/ico" href="../assets/favicon.png">
    <!-- CSS -->
    <link rel="stylesheet" href="../assets/css/main.css" />
  </head>
  <body id ="Site" class='layout-reverse theme-base-sm sidebar-overlay'>
    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
      content to avoid any CSS collisions with our real content. -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <div class="navbar navbar-expand-sm navbar-default navbar-fixed-top" role="navigation">
      <div class="container" id="nav-container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="../">SIMSSA</a>
        </div>
        <div class="collapse navbar-collapse">
          <ul class="navbar-nav nav mr-auto">
            <li><a href="../about">About</a></li>
            <li><a href="../../people">Participants</a></li>
            <li class="dropdown">
              <a class="dropdown-toggle" role="button" data-toggle="dropdown" href="#">Activities<span class="caret"></span></a>
              <ul class="dropdown-menu" role="menu">
                <li><a href='../activities/corpora-and-datasets/' target='_top' >Datasets and Corpora</a></li>
                <li><a href='../../activities/impact/' target='_top' >Our impact</a></li>
                <li><a href='../../activities/media/' target='_top' >Media</a></li>
                <li><a href='../../activities/presentations/' target='_top' >Presentations</a></li>
                <li><a href='../../activities/publications/' target='_top' >Publications</a></li>
                <li><a href='../../activities/workshops/' target='_top' >Workshops</a></li>
              </ul>
            </li>
            <li class="dropdown">
              <a class="dropdown-toggle" role="button" data-toggle="dropdown" href="#">Projects and links<span class="caret"></span></a>
              <ul class="dropdown-menu" role="menu">
                <li><a href='http://cantus.simssa.ca/' target='_top' >Cantus Ultimus</a></li>
                <li><a href='' target='_top' >ELVIS Project</a></li>
                <li><a href='http://jmir.sourceforge.net/index_jSymbolic.html' target='_top' >jSymbolic2</a></li>
                <li><a href='http://liber.simssa.ca' target='_top' >Liber Usualis</a></li>
                <li><a href='https://github.com/DDMAL/Andrew-Hughes-Chant' target='_top' >LMLO</a></li>
                <li><a href='' target='_top' >Musiclibs</a></li>
                <li><a href='http://ddmal.teamwork.com/' target='_top' >Teamwork</a></li>
                <hr id="menu-divider">
                <li><a href="http://github.com/DDMAL" target="_blank">Github</a></li>
                <li><a href="http://twitter.com/simssaproject" target="_blank">Twitter</a></li>
              </ul>
            </li>
            <li><a href="">Blog</a></li>
            <li><a href="../opportunities">Opportunities</a></li>
            <li><a href="../contact">Contact us</a></li>
          </ul>
        </div>
      </div>
    </div>
    <section class="headerimage">
      <div class="container">
        <br>
        <br>
        <h1>Blog</h1>
      </div>
    </section>
    <div class="container">
      <div class="row">
        <div class="col-lg-12">
          <h2><a href="../blog/MMLworkshop/">Music and Machine Learning Workshop</a></h2>
          <br>
          <p> Posted by ehopkins on December 22, 2021</p>
          <br>
          <div class="post-excerpt">
            <p>On 15 December 2021, the 14th annual <a href="https://sites.google.com/view/mml-2021/home">Music and Machine Learning Workshop</a> was held online, hosted by Rafael Ramirez (Universitat Pompeu Fabra, Spain), Darrell Conklin (University of the Basque Country, Spain), and José Manuel Iñesta (University of Alicante, Spain). This blog post is a really brief overview of the presentations; for more check out the <a href="https://ehubox.ehu.eus/s/qQXQzLqPtg792RM">Proceedings</a> online.</p>
            <p>José Manual Iñesta (pictured below) is also a visiting professor here at McGill this year, and a few members of our lab participated in the workshop too.</p>
            <p></p>
            <p>There were approximately 20 participants in the workshop, with topics including Roman Numeral Analysis, Optical Music Recognition, music demixing, and ways that music and machine learning draw on language, machine translation, and bioinformatics technologies. Each presentations was a quick 8 minutes followed by questions to give everyone a chance to catch up on each other’s research.</p>
            MultiScore Project: Multimodal Transcription of Music Scores...
          </div>
          <br />
          <p>
            <a href="../blog/MMLworkshop/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/ismir2019/">ISMIR 2019: Delft</a></h2>
          <br>
          <p> Posted by ehopkins on December 16, 2019</p>
          <br>
          <div class="post-excerpt">
            <p>Back at the beginning of November, several members of our lab made the journey to the Netherlands to attend and present at <a href="https://ismir2019.ewi.tudelft.nl/">ISMIR2019</a> and related satellite conferences. (ISMIR was from Nov. 4-8 with satellites before and after). Delft was a really neat city to visit, with as many bicycles, canals, and pounds of black licorice you could ever want…</p>
            <p></p>
            <p>We will be hosting <a href="https://ismir.github.io/ISMIR2020/">ISMIR2020</a> here in Montreal so it was also great to see the ever-growing conference in action! (It was my first ISMIR too.)</p>
            <p></p>
            <p>Satellites before the conference included WoRMS, WiMIR, and the first-ever Workshop on Designing Human-Centric MIR systems. We had presenters at two of these, and a few of our students attended the WiMIR hackathon event as well.</p>
            Workshop on Reading Music Systems (WoRMS)
            <p>This was the second year for WoRMS – former SIMSSA postdoc Jorge Calvo-Zaraogoza is one of the chairs. PhD...
          </div>
          <br />
          <p>
            <a href="../blog/ismir2019/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/simssa-xix/">SIMSSA XIX: Introducing DACT and MML16</a></h2>
          <br>
          <p> Posted by ehopkins on December 11, 2019</p>
          <br>
          <div class="post-excerpt">
            <p>On 21 September 2019, we had our 19th SIMSSA workshop, this time here at McGill in collaboration with <a href="https://www.cirmmt.org">CIRMMT</a>. This weekend coincided with a workshop for Julie Cumming’s new SSHRC Grant, Mapping the Musical Landscape of the 16th Century (MML16), as well as Jennifer Bain’s new partnership grant, Digital Analysis of Chant Transmission (DACT). Scholars involved in all three projects were here for a few days to make plans and exchange ideas, and the SIMSSA Workshop had around 45 attendees.</p>
            <p></p>
            <p>Ichiro Fujinaga: Welcome &amp; Introduction As always, Ich started the day with an overview of recent SIMSSA highlights, including workshops and other major projects. (Slides: <a href="../assets/files/fujinaga_2019_simssaxix_intro_slides.key">Keynote</a> and <a href="../assets/files/fujinaga_2019_simssaxix_intro_slides.pdf">PDF</a>) </p>
            <p>Jennifer Bain: The Digital Analysis of Chant Transmission (DACT) Jennifer presented on her new SSHRC Partnership DACT! Now that Cantus Ultimus has ended, we’re excited to see where this new venture goes. (Slides: <a href="../assets/files/bain_2019_simssaxix_dact_slides.pdf">PDF</a> and <a...
          </div>
          <br />
          <p>
            <a href="../blog/simssa-xix/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/simssa_xvii/">SIMSSA XVII: Infrastructure for Music Discovery</a></h2>
          <br>
          <p> Posted by ehopkins on December 01, 2018</p>
          <br>
          <div class="post-excerpt">
            <p></p>
            <p>Earlier this month we had our seventeenth SIMSSA workshop, this time here at McGill in collaboration with <a href="https://www.cirmmt.org">CIRMMT</a>). Sally Jo Cunningham gave a CIRMMT Distinguished Lecture earlier that week on <a href="https://www.cirmmt.org/activities/distinguished-lectures/sally-jo-cunningham">Engagement with Personal Music Collections</a> which inspired our theme: Infrastructure for Music Discovery. We had 19 different speakers covering everything from OMR to library reference models to linked data to country music! Here is a roundup of all the presenter’s slides and some pictures from the event.</p>
            <p>To start the day, Ichiro Fujinaga gave us an overview of the project, including the most recent workshops and other activities. (Slides: <a href="../assets/files/fujinaga1-simssaxvii.pdf">PDF</a>). After that, I (Emily Hopkins) gave an introduction to the different components of the SIMSSA project, explaining how they all come together in context. (Slides: <a href="../assets/files/hopkins1-simssaxvii.pptx">Powerpoint</a> and <a href="../assets/files/hopkins1-simssaxvii.pdf">PDF</a>)</p>
            <p>Next, we had several updates from students working in the DDMAL labs on various parts of...
          </div>
          <br />
          <p>
            <a href="../blog/simssa_xvii/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/DLfM-becky-shaw/">Visiting Paris with Becky Shaw: DLfM 2018</a></h2>
          <br>
          <p> Posted by ehopkins on October 31, 2018</p>
          <br>
          <div class="post-excerpt">
            <p>The International Society for Music Information Retrieval conference (<a href="http://ismir2018.ircam.fr/">ISMIR 2018</a>) was held in Paris this year, and several SIMSSA researchers shared their work at both ISMIR and the satellite conferences. These include SIMSSA Collaborator Jorge Calvo-Zaragoza’s brand-new <a href="https://sites.google.com/view/worms2018/people">WoRMS</a> conference (Workshop on Reading Music Systems) as well as <a href="https://dlfm.web.ox.ac.uk/">DLfM</a>, the International Conference on Digital Libraries for Musicology.</p>
            <p>Becky Shaw has been a SIMSSA and Cantus Ultimus participant since 2016, working at SIMSSA Partner Dalhousie University, pursuing musicology and library science education while learning more about chant and digital tools for musicology.</p>
            <p>This September, Becky went to <a href="https://dlfm.web.ox.ac.uk/">DLfM</a> to share her research, presenting on <a href="../../assets/files/DLfM_Presentation_Shaw.pdf">Differentiae in the Cantus Manuscript Database: Standardization and Musicological Application</a>. Her work focuses on psalm differentia, the different endings to a psalm that can be used to make a smooth transition to the following antiphon. I got to ask her some questions about...
          </div>
          <br />
          <p>
            <a href="../blog/DLfM-becky-shaw/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/simssa-xv-in-leipzig/">A Trip to Leipzig: SIMSSA XV and IAML</a></h2>
          <br>
          <p> Posted by ehopkins on August 30, 2018</p>
          <br>
          <div class="post-excerpt">
            <p>Our fifteenth SIMSSA Workshop took place in Leipzig on 28 July 2018 immediately following the annual congress of the <a href="http://iaml2018.info/home/">International Association of Music Librarians</a>! Many of our partners and collaborators work in music libraries so it was a great chance to meet some of them and update each other on our work. In addition to my work for SIMSSA, I am also doing my MLIS, so it was really wonderful to get to meet so many people working on different aspects of librarianship and music. It was also fascinating to get a chance to learn more about Leipzig’s history as a centre for classical music and also as part of East Germany.</p>
            <p></p>
            <p>The Nikolaikirche downtown. Bach worked here as well as the St. Thomas church, and it was also the site of the Monday demonstrations, peaceful protests against the German Democratic Republic from 1989-1991.</p>
            <p>The IAML Congress started...
          </div>
          <br />
          <p>
            <a href="../blog/simssa-xv-in-leipzig/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/Workshop-on-SIMSSA-XIV/">SIMSSA XIV at McGill</a></h2>
          <br>
          <p> Posted by ehopkins on June 25, 2018</p>
          <br>
          <div class="post-excerpt">
            <p>At the end of May, we were pleased to host our fourteenth SIMSSA Workshop! Held at McGill University, our guest speakers included Andy Irving (<a href="https://www.bl.uk/projects/save-our-sounds">British Library</a>), Laurent Pugin (<a href="http://rism-ch.org/">RISM-Switzerland</a>), Jorge Calvo-Zaragoza (<a href="https://www.upv.es/index-en.html">Universitat Politècnica de Valencia</a>, and Andrew Hankinson (<a href="https://www.bodleian.ox.ac.uk/">Bodleian Libraries at Oxford</a>.) We also heard presentations from our summer students, who are developing SIMSSA software full-time in the DDMAL lab from May through August.</p>
            <p>First up, we had Andy Irving present on <a href="../../assets/files/UOSH-IIIF-AV-BL.pdf">Unlocking our sound heritage: IIIF AV at the BL</a>.</p>
            <p></p>
            <p><a href="http://iiif.io/">IIIF</a> may be familiar to many SIMSSA folks at this point – it’s the International Image Interoperability Framework. This technology is what enables <a href="https://musiclibs.net">MusicLibs</a>, where we serve searchable IIIF manifests of score images that are still hosted at their home institutions. <a href="http://iiif.io/community/groups/av/">IIIF AV</a> involves extending this concept to audio and video materials, including creating a Universal Player. Andy presented on...
          </div>
          <br />
          <p>
            <a href="../blog/Workshop-on-SIMSSA-XIV/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/Workshop-on-digital-musicology/">Workshop on Digital Musicology</a></h2>
          <br>
          <p> Posted by ehopkins on May 04, 2018</p>
          <br>
          <div class="post-excerpt">
            <p>On 27 April, we held a workshop with <a href="https://www.cirmmt.org/">CIRMMT</a> RA 2 – Music Information Research. This workshop was designed as a companion to Eleanor Selfridge-Field’s CIRMMT Distinguished Lecture. Unfortunately her visit to Montreal had to be cancelled but we were able to hold the workshop anyways, and I’ve included all the slides here for anyone who was not able to attend but wants to know more!</p>
            <p></p>
            <p>The first presentation was from Claire Arthur, based on work done towards a chapter in the forthcoming Oxford Handbook of Music and Corpus Studies with Peter Schubert and Julie Cumming. The presentation was titled <a href="../assets/files/claire-arthur-april27.pptx">“Whose Line is it Anyway?: Assessing Melodic Features of Mode in Polyphony.”</a> For this presentation, Claire described their study’s investigation of the nature of mode in polyphonic music. Using 44 Renaissance duos with modal labels taken from treatises and didactic collections, they examined which features were best...
          </div>
          <br />
          <p>
            <a href="../blog/Workshop-on-digital-musicology/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/johanna-devaney/">An Interview with Johanna Devaney</a></h2>
          <br>
          <p> Posted by ehopkins on April 12, 2018</p>
          <br>
          <div class="post-excerpt">
            <p><a href="http://www.devaney.ca">Johanna Devaney</a> is Assistant Professor of Music Theory and Cognition at <a href="https://music.osu.edu/people/devaney.12">Ohio State University</a>, currently teaching in the <a href="https://steinhardt.nyu.edu/music/technology">music technology program at NYU</a>, and the newest SIMSSA Collaborator. We had a chance to talk over Skype about music and the digital humanities, learning to program, and the ways that music research can drive technological advances even beyond disciplinary bounds.</p>
            <p></p>
            <p>EH: Thank you so much for agreeing to talk with me today. We’re pretty excited to have you on board as a SIMSSA collaborator. Since music information retrieval as I’ve experienced it attracts folks with a lot of different disciplinary interests, I’m always curious about the paths people have taken to end up here. I looked at your CV and it looks like you started out playing piano and oboe and doing some composing, and then you did a BFA in music and history, and then a...
          </div>
          <br />
          <p>
            <a href="../blog/johanna-devaney/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/interviewing-martha/">Digital Encoding of Mensural Music: an Interview with Martha Thomae</a></h2>
          <br>
          <p> Posted by ehopkins on January 19, 2018</p>
          <br>
          <div class="post-excerpt">
            <p>Martha Thomae is a PhD student in the Music Tech Department, working on mensural notation for the SIMSSA Project. Originally from Guatemala, she came to Montreal for her Master’s in Music Technology in 2015 and she started her PhD here this past fall. She’s pictured below at the beach in Calahonda, Motril, in the Granada province of Spain. Music Theory PhD student Sam Howes (read our interview with him in 2016 <a href="http://simssa.ca/blog/from-module-to-schema-an-interview-with-sam-howes">here</a>) interviewed her about her work on her Master’s thesis and some more current projects.</p>
            <p></p>
            <p>Sam Howes: Most musicians today have never seen mensural music. Could you give us a little introduction to this method of music notation?</p>
            <p>Martha Thomae: Sure, mensural music refers to music written in mensural notation, a system that was used between the 1250s and the 1600s for vocal polyphonic music. Mensural notation is the immediate predecessor of our common Western music notation...
          </div>
          <br />
          <p>
            <a href="../blog/interviewing-martha/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/GREC/">Tackling OMR in Kyoto: SIMSSA at GREC 2017</a></h2>
          <br>
          <p> Posted by ehopkins on November 22, 2017</p>
          <br>
          <div class="post-excerpt">
            <p>Earlier this month, four SIMSSA Participants visited Kyoto for the 12th IAPR International Workshop on Graphics Recognition (<a href="http://grec2017.loria.fr/">GREC 2017</a>). This conference was held in conjunction with the International Conference on Document Analysis and Recognition (<a href="http://u-pat.org/ICDAR2017/index.php">ICDAR</a>, in its 14th edition).</p>
            <p>Project Director Ichiro Fujinaga was the <a href="http://www.iapr.org/index.php">IAPR</a> invited speaker, and gave a talk on the history of OMR titled “A Retrospective on Optical Music Recognition Research”, detailing the history of OMR since the 1960s.</p>
            <p></p>
            <p>SIMSSA Postdoc Jorge Calvo-Zaragoza presented some recent work, co-authored with Ké Zhang, Zeyad Saleh, Gabriel Vigliensoni, and Ichiro Fujinaga: <a href="../assets/files/GREC2017-Jorge.pdf">Music Document Layout Analysis through Machine Learning and Human Feedback</a>.</p>
            <p></p>
            <p>Finally, we were very proud to send two of the undergraduates we hired last summer! You might remember Ké and Zeyad from <a href="https://simssa.ca/blog/introducing-the-ddmal-summer-workers">this post last May</a>, when they were just getting started on <a href="https://github.com/ddmal/pixel.js">Pixel.js</a>. Here they are below, demonstrating their...
          </div>
          <br />
          <p>
            <a href="../blog/GREC/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/SIMSSA-at-ISMIR-in-Suzhou/">SIMSSA in Suzhou: ISMIR and DLfM 2017</a></h2>
          <br>
          <p> Posted by ehopkins on October 31, 2017</p>
          <br>
          <div class="post-excerpt">
            <p>Last week, several SIMSSA participants presented their latest research in Suzhou and Shanghai, China, at <a href="https://ismir2017.smcnus.org/">ISMIR</a> (International Society for Music Information Retrieval) and its Satellite conference, <a href="http://www.transforming-musicology.org/dlfm2017/#workshop-programme">DLfM</a> (Digital Libraries for Musicology.)</p>
            <p>SIMSSA Postdoc Jorge Calvo-Zaragoza presented a poster on <a href="../assets/files/jorge-ismir2017.pdf">“End-to-End Optical Music Recognition Using Neural Networks”</a> co-authored by Jose J. Valero-Mas and Antonio Pertusa, colleagues from the University of Alicante. </p>
            <p>Jorge had a second poster with SIMSSA Postdoc Gabriel Vigliensoni and PD Ichiro Fujinaga – this one on <a href="../assets/files/jorge-gabriel-ismir2017.pdf">“One-Step Detection of Background, Staff Lines, and Symbols in Medieval Music Manuscripts with Convolutional Neural Networks”</a>. </p>
            <p>Gabriel finished his PhD at McGill this past spring, and also gave a presentation to introduce and launch a dataset he assembled for his dissertation, <a href="../assets/files/gabriel-MLHD-ismir2017.pdf">“The Music Listening Histories Dataset.”</a> Including more than 27 billion time-stamped logs from Last.fm, it is now available online for you to access and...
          </div>
          <br />
          <p>
            <a href="../blog/SIMSSA-at-ISMIR-in-Suzhou/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/introducing-Nat/">Introducing Nat Condit-Schultz</a></h2>
          <br>
          <p> Posted by ehopkins on August 29, 2017</p>
          <br>
          <div class="post-excerpt">
            <p>Nat Condit-Schultz began his work with the SIMSSA project as a <a href="http://www.cirmmt.org/">CIRMMT</a> Visiting Scholar in the summer of 2016, and now joins us as a new postdoc for our Analysis axis.</p>
            <p>Emily Hopkins: Where are you originally from? What are some highlights: places you’ve lived, schools you’ve studied at, jobs you’ve done?</p>
            <p>Nat Condit-Schultz: I was born and lived my earliest years in Massachussetts and New Jersey, but the first place I lived that I was old enough to remember was in the Republic of Panama. My dad worked as a biologist for the Smithsonian Tropical Research Institute in Panama (a US government project) for 25 years, and we lived there with him from when I was 3-9, and went back to visit frequently after that. We lived in a small town called Gamboa, which was built by the United States in the 1930s as a place for US...
          </div>
          <br />
          <p>
            <a href="../blog/introducing-Nat/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/SIMSSAXII/">Building the OMR Workflow: Workshop on SIMSSA XII</a></h2>
          <br>
          <p> Posted by ehopkins on August 17, 2017</p>
          <br>
          <div class="post-excerpt">
            <p>On August 7, 2017, we held the twelfth workshop on SIMSSA at the Schulich School of Music here in Montreal. Many of our SIMSSA Community members were in town for <a href="https://dh2017.adho.org/">DH2017</a> so it was a great opportunity to share what everyone’s been working on, including the progress from our <a href="https://simssa.ca/blog/introducing-the-ddmal-summer-workers">DDMAL summer development team</a>.</p>
            <p>We started the morning with an introduction to the SIMSSA Project from Prof. Ichiro Fujinaga, who also introduced our keynote, SIMSSA Collaborator Craig Sapp. Craig gave a keynote introducing the <a href="http://verovio.humdrum.org/">Verovio-Humdrum Viewer</a>. This online viewer allows users to edit a kern or MEI file and see changes in the score in real time, as well as other features demonstrated in his slides <a href="https://docs.google.com/presentation/d/1QR-XkMbJrqgmG5Hxyysf1SxObW7SR_WC0LO3Mh-L7Qs/edit#slide=id.p6">here</a>. Below, the top voice of a Bach chorale is extracted for study in the viewer:</p>
            <p></p>
            <p>Then, we had two more featured speakers. Andrew Hankinson, former SIMSSA postdoc and newly...
          </div>
          <br />
          <p>
            <a href="../blog/SIMSSAXII/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/tripoli-blog/">Tripoli at IIIF Conference in the Vatican</a></h2>
          <br>
          <p> Posted by ehopkins on August 02, 2017</p>
          <br>
          <div class="post-excerpt">
            <p>Alex Parmentier worked in the DDMAL Lab when he was a McGill undergrad, working on the <a href="https://database.elvisproject.ca/">ELVIS Database</a>, <a href="https://musiclibs.net/">Musiclibs</a>, and more from 2015-17. He recently graduated from McGill, and now works for <a href="https://www.amilia.com/en">Amilia</a> here in Montreal. This summer he visited the Vatican to present his research at the IIIF conference, and he’s taken the time to share his experience in a blog post for us. Thanks Alex!</p>
            <p>In early June I traveled to the <a href="http://iiif.io/event/2017/vatican/">IIIF conference in the Vatican</a> to present my work on <a href="https://github.com/DDMAL/tripoli">Tripoli</a>, a IIIF Presentation API validator and corrector.</p>
            <p></p>
            <p>The IIIF conference is a yearly gathering of developers and librarians who work with IIIF, a framework which, among other features, facilitates the publishing and consuming of archival quality images. IIIF allows libraries to make their high-quality image resources publicly available and affords a great deal of freedom to users to collect,...
          </div>
          <br />
          <p>
            <a href="../blog/tripoli-blog/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/introducing-the-ddmal-summer-workers/">Introducing the DDMAL Summer Workers!</a></h2>
          <br>
          <p> Posted by ehopkins on May 30, 2017</p>
          <br>
          <div class="post-excerpt">
            <p>During the Summer, the SIMSSA team at McGill expands as we hire several undergraduate students to work full-time on projects over the summer. Since SIMSSA is such an interdisciplinary project, we usually attract a wide range of really interesting backgrounds and skillsets, and this year is no exception! This summer, we’re focussing on the OMR side of the project (the Content Axis) and we have six new faces in the lab, so I thought it would be fun to introduce them.</p>
            <p></p>
            <p><a href="https://github.com/ATranimal">Andrew Tran</a> (left) and <a href="https://github.com/zoemcl">Zoé McLennan</a> (right) are working on <a href="https://github.com/DDMAL/Neon.js">Neon.js</a>, a web-based editor for digitally encoded early music scores. They’re extending its current functionality, including being able to edit staffless scores.</p>
            <p>Emily Hopkins: What appealed to you about working for SIMSSA?</p>
            <p>Andrew Tran: As a programmer who also has a strong passion for music, I’ve always been interested in the field of music technology....
          </div>
          <br />
          <p>
            <a href="../blog/introducing-the-ddmal-summer-workers/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/jsymbolic2-released/">jSymbolic2 Released!</a></h2>
          <br>
          <p> Posted by ehopkins on May 18, 2017</p>
          <br>
          <div class="post-excerpt">
            <p>We are pleased to release <a href="http://jmir.sourceforge.net/index_jSymbolic.html">jSymbolic2</a>, a research software application for extracting features (characteristic statistical information) from musical data stored symbolically in file formats such as MIDI or <a href="http://music-encoding.org/">MEI</a>. These features may be fed directly into automatic classification systems, may be used to query large musical databases, or may be used by musicologists and music theorists for conducting empirical music research.</p>
            <p> The jSymbolic2 graphical interface</p>
            <p>The software is packaged with 172 unique features, far more than any other existing software. Some of these features are multi-dimensional, for a total of 1230 combined feature values. These features may be used directly for conducting research, or the software may be used as a platform for iteratively developing new features that can then be shared amongst researchers. As such, jSymbolic2 emphasizes extensibility, and includes a modular design that facilitates the implementation and incorporation of new features.</p>
            <p>jSymbolic2 is part of...
          </div>
          <br />
          <p>
            <a href="../blog/jsymbolic2-released/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/simssa-workshop-x/">SIMSSA Workshop X</a></h2>
          <br>
          <p> Posted by neshraghi on November 07, 2016</p>
          <br>
          <div class="post-excerpt">
            <p>The tenth SIMSSA Workshop, hosted by the Centre for Interdisciplinary Research in Music Media and Technology <a href="http://www.cirmmt.org/">CIRMMT</a> at McGill University, took place on Saturday, September 24, 2016. These workshops started out as demonstrations of current research interests and technologies being developed by graduate students and professional scholars. Bringing together experts from many different disciplines, including music technology, music theory, music cognition, musicology, and others, SIMSSA Workshops continue to demonstrate cutting-edge advancements in the field of music today.</p>
            <p></p>
            Ichiro Fujinaga – Introduction to SIMSSA Workshop X
            <p>The morning began with an introduction from Professor Ichiro Fujinaga, the principal investigator of the SIMSSA grant. He discussed the history of previous SIMSSA workshops, previous visiting scholars to SIMSSA—such as Leigh van Handel, Jorge Calvo-Zaragoze, and many more—and papers and talks generated by the SIMSSA community that staggeringly number 45 (not counting those that are forthcoming). Some of the big news that...
          </div>
          <br />
          <p>
            <a href="../blog/simssa-workshop-x/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/interview-with-ian-lorenz/">Gombert, Rodan, and CRIM: an interview with Ian Lorenz</a></h2>
          <br>
          <p> Posted by ehopkins on August 16, 2016</p>
          <br>
          <div class="post-excerpt">
            <p>Today’s post comes to us from Musicology PhD student Ian Lorenz. Entering his second year working with Julie Cumming and Peter Schubert, he’s working on a project using SIMSSA software to investigate lesser-known 16th-century composer Nicolas Gombert.</p>
            <p></p>
            <p>Emily Hopkins: How did you first become interested in using computers for music research? Had you done it at all before coming to McGill?</p>
            <p>Ian Lorenz: I had not used computers in my music research prior to arriving at McGill. The research that I was involved in for my Master’s degree investigated modality in the music of the fifteenth century, in which I analyzed all of the secular works by Gilles Binchois, Guillaume Dufay, Johannes Ockeghem, Antoine Busnoys, and Johannes Tinctoris by hand. Since coming to McGill, however, I have learned about the expediency of working with computers when working on large-scale corpus studies.</p>
            <p>EH: How did you become interested in Gombert?...
          </div>
          <br />
          <p>
            <a href="../blog/interview-with-ian-lorenz/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/introducing-claire-arthur/">A Systematic Musicologist for Life: Introducing Claire Arthur</a></h2>
          <br>
          <p> Posted by ehopkins on August 02, 2016</p>
          <br>
          <div class="post-excerpt">
            <p>In today’s post, I’m excited to introduce our new post-doc, Claire Arthur! She comes to us most recently from Ohio State University, where she defended her dissertation this past May working under David Huron. She’ll be heading up our analysis axis alongside Julie Cumming and continuing postdoc Reiner Krämer. She’s pictured below in Athens, Greece.</p>
            <p></p>
            <p>Emily Hopkins: Where are you originally from? What are some highlights: places you’ve lived, schools you’ve studied at, jobs you’ve done?</p>
            <p>Claire Arthur: I grew up in Dundas, Ontario, close to McMaster University. I did my undergrad at the <a href="https://www.music.utoronto.ca/">University of Toronto</a>, and my master’s at the <a href="http://music.ubc.ca/">University of British Columbia</a>. I spent most of my life as a young adult waitressing to pay my way through school. My favourite waitressing gig was at Joe’s Grill in Vancouver, BC – great breakfast joint!</p>
            <p>EH: How did you first hear about SIMSSA?</p>
            <p>CA:...
          </div>
          <br />
          <p>
            <a href="../blog/introducing-claire-arthur/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/from-module-to-schema-an-interview-with-sam-howes/">From Module to Schema: an interview with Sam Howes</a></h2>
          <br>
          <p> Posted by ehopkins on July 11, 2016</p>
          <br>
          <div class="post-excerpt">
            <p>Sam Howes is a PhD student in Music Theory at McGill, and a researcher for the SIMSSA project. He recently presented a paper at the <a href="http://www.music.indiana.edu/departments/academic/music-theory/SMT%20Early%20Music%20Analysis%20Interest%20Group%20Conference.shtml">SMT Early Music Analysis Interest Group Conference in Indiana</a>, “From Module to Schema in Corelli’s Trio Sonatas.” I interviewed him for the blog to talk about his research and his experiences with computer music analysis and SIMSSA.</p>
            <p></p>
            <p>Emily Hopkins: When did you first become interested in using computers to do musical analysis?</p>
            <p>Sam Howes: In the summer of 2015 I took an introductory computer science course and around that same time, I discovered Peter Schubert’s <a href="https://www.youtube.com/watch?v=n01J393WpKk">“Improvising a Canon”</a> videos on Youtube. The simple description of melodic rules in those videos is what first helped me realize that strict counterpoint can be generated, and even queried, algorithmically.</p>
            <p>EH: What was the main research question for this project?</p>
            <p>SH: My aim was to better...
          </div>
          <br />
          <p>
            <a href="../blog/from-module-to-schema-an-interview-with-sam-howes/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/music-encoding/">The Music Encoding Conference</a></h2>
          <br>
          <p> Posted by ehopkins on June 23, 2016</p>
          <br>
          <div class="post-excerpt">
            <p>One month ago, the SIMSSA Project and the <a href="https://www.mcgill.ca/music/about-us">Schulich School of Music</a> had the privilege of hosting the fourth annual <a href="http://music-encoding.org/community/conference/">Music Encoding Conference</a>, organized by the <a href="http://music-encoding.org/">Music Encoding Initiative</a>. This year’s conference included nearly 70 delegates from 10 different countries, including about a dozen students.</p>
            <p> Participants gathered between activities in the Wirth Music Building lobby.</p>
            <p>The full conference program is available as a PDF <a href="../assets/files/MEC2016Program.pdf">here</a>. The conference started with workshops on recent developments in <a href="http://www.verovio.org/index.xhtml">Verovio</a> with <a href="http://rism-ch.org/contact.html">Laurent Pugin</a>, an Introduction to MEI with <a href="http://people.virginia.edu/~pdr4h/resume2.html">Perry Roland</a>, and “Encoding Music at Music Encoding” with <a href="http://blog.jdlh.com/">Jim DeLaHunt</a>.</p>
            <p>We opened the first day of papers with a message from our Dean, followed by <a href="http://www.northeastern.edu/cssh/faculty/julia-flanders">Julia Flanders</a>’ keynote, The Provocation of Music: Evolving Paradigms for Markup. The conference featured 20 papers presented over two days. Below, <a href="http://music.uwo.ca/faculty/faculty_staff/bios/k_helsen.html">Kate Helsen</a> presents Hartker’s XML: The Optical Neume Recognition...
          </div>
          <br />
          <p>
            <a href="../blog/music-encoding/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/troubadour-melodies-database/">Troubadour Melodies Database</a></h2>
          <br>
          <p> Posted by ehopkins on March 21, 2016</p>
          <br>
          <div class="post-excerpt">
            <p>Today’s blog post features the <a href="http://www.troubadourmelodies.org/">Troubadour Melodies Database</a>, a project developed by Katie Chapman that uses tools and resources developed through SIMSSA and the <a href="http://cantus.simssa.ca/">Cantus Ultimus</a> project. Working with <a href="http://kolacek.org/">Jan Koláček</a>, one of our international SIMSSA collaborators, she has developed a fully searchable online database of troubadour melodies encoded in the <a href="http://www.uni-regensburg.de/Fakultaeten/phil_Fak_I/Musikwissenschaft/cantus/volpiano.html">Volpiano font</a>. Katie is currently a PhD candidate in Musicology at <a href="http://music.indiana.edu/departments/academic/musicology/">Indiana University</a>. Originally from Rock Hill, South Carolina, she also studied Music Theory and History at Furman University (Greenville, SC) and performed on bassoon and contrabassoon.</p>
            <p></p>
            <p>Emily Hopkins: What inspired the creation of the database? Can you tell us more about how you are using the database in your dissertation research?</p>
            <p>Katie Chapman: One of the first inspirations for the database came from Hans Tischler, who described the benefit of having a team bring together study of the different lyric traditions to...
          </div>
          <br />
          <p>
            <a href="../blog/troubadour-melodies-database/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/simssa-at-dalhousie/">SIMSSA at Dalhousie!</a></h2>
          <br>
          <p> Posted by ehopkins on February 29, 2016</p>
          <br>
          <div class="post-excerpt">
            <p>Hello everyone! Things have been a little quiet on the blog, but there’s lots of interesting things coming up soon. First among these is a post about SIMSSA-related work going on at <a href="http://www.dal.ca/faculty/arts/school-of-performing-arts.html">Dalhousie</a>. I work at McGill, and most of the guest posts so far have been from McGill developers and post-docs, but people work on SIMSSA <a href="https://simssa.ca/people">all over the place</a>. Many thanks to Jennifer Bain, one of our Co-Investigators, who is at Dalhousie and helped connect me to some of their researchers. I interviewed a few of them over email so you can all get to know them and their work at Dalhousie a little better.</p>
            <p>First up is Barbara Swanson. Currently a postdoctoral fellow at York University, she was a postdoc at Dalhousie in 2014-15 and continues to work on the SIMSSA project with current Dalhousie students. Originally from Regina, SK, Barbara has lived in Halifax,...
          </div>
          <br />
          <p>
            <a href="../blog/simssa-at-dalhousie/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/the-human-history-project/">The Human History Project</a></h2>
          <br>
          <p> Posted by ehopkins on December 17, 2015</p>
          <br>
          <div class="post-excerpt">
            <p>Today’s post marks the occasion of the <a href="http://www.cirmmt.org/activities/workshops/research/human_history_project_2/hpp">Second International Workshop on the Human History Project</a>, which took place a week ago on Saturday, December 12. While not specifically SIMSSA-related, this is an exciting Digital Humanities project, and many of our researchers are also involved in it. I was able to attend so I could write this post and provide you some highlights from the day.</p>
            <p>The premise of the Human History Project is simple enough: store the entirety of documented human history in a single database, accessible online. Books, receipts, newspaper articles, lists, anything and everything. Carrying this out, however, is a long and involved process. Some key concepts are:</p>
            Using Natural Language Processing: for handling large amounts of unstructured data. Named-entity extraction, events extraction, etc. Linked open data: using <a href="http://www.w3.org/RDF/">Resource Description Framework</a> (RDF) and querying with <a href="http://www.w3.org/TR/rdf-sparql-query/">SPARQL</a> Crowdsourcing
            <p>The event was well-attended and featured several guest...
          </div>
          <br />
          <p>
            <a href="../blog/the-human-history-project/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/simssa-and-dream/">Reanimating Corpora: SIMSSA and DREaM</a></h2>
          <br>
          <p> Posted by ehopkins on November 18, 2015</p>
          <br>
          <div class="post-excerpt">
            <p>Last Thursday, SIMSSA participated in the Works in Progress series for <a href="http://digihum.mcgill.ca/">McGill Digital Humanities</a>, alongside the <a href="http://earlymodernconversions.com/introducing-dream/">DREaM Project</a>. In “Reanimating Corpora: The Single Interface for Music Score Searching and Analysis (SIMSSA) and Distant Reading Early Modernity (DREaM)”, researchers from DREaM and SIMSSA shared some of their latest developments and talked about challenges in common when making decisions about how to organize large corpora, whether written texts or musical scores.</p>
            <p>SIMSSA started things off, with an <a href="../assets/files/fujinaga15DHWiP1.pdf">overview of SIMSSA</a> presented by Ichiro Fujinaga, our PI and Content Axis leader. He discussed the process of Optical Music Recognition, and what goes into developing the viewing and searching capacities for the interface we’re working towards.</p>
            <p>Next up, Alexander Morgan gave a presentation on <a href="../assets/files/AlexMIntegralAnalysisDHNov2015.pdf">“Integral Analysis in VIS.”</a> He talked about clustering composers’ work by comparing the similarity of the intervallic content of their works, demonstrating this technique with a...
          </div>
          <br />
          <p>
            <a href="../blog/simssa-and-dream/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/machine-learning-in-music-analysis/">Machine Learning in Music Analysis</a></h2>
          <br>
          <p> Posted by ehopkins on November 06, 2015</p>
          <br>
          <div class="post-excerpt">
            <p>Reiner Krämer has been working with SIMSSA as a Postdoc since July, and has been presenting on some of the work he’s done, most recently at <a href="https://societymusictheory.org/">SMT</a>. Today’s post is a guest entry from Reiner, explaining some of his recent work and its implications for music theory and musicology research.</p>
            <p>Using machine learning techniques as a compositional tool in music is almost as old as writing computer programs itself. When in 1957 Lejaren Hiller and Leonard Isaacson composed the Illiac Suite (also know as String Quartet No. 4), the researchers employed probability (p) tables generated that were used for Markov chain computations.<a href="#fn:1" class="footnote" rel="footnote">1</a> One of the main ideas behind Markov models is how to randomly move from on state to another. The task is statistically achieved by creating state transition matrices (STMs). A STM keeps a tally of how many times a state is changed from one...
          </div>
          <br />
          <p>
            <a href="../blog/machine-learning-in-music-analysis/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/cirmmt-workshop-on-usability-and-user-experience-for-music-information-systems/">CIRMMT Workshop: Masataka Goto visits McGill</a></h2>
          <br>
          <p> Posted by ehopkins on October 16, 2015</p>
          <br>
          <div class="post-excerpt">
            <p>As part of <a href="http://www.cirmmt.org/activities/distinguished-lectures">CIRMMT’s Distinguished Lectures series</a>, <a href="https://staff.aist.go.jp/m.goto/">Masataka Goto</a> visited McGill University. He gave a talk on Thursday afternoon, and the next day introduced the<a href="http://www.cirmmt.org/activities/workshops/research/usability2015/hpp"> CIRMMT Workshop on usability and user experience for music information systems</a> where many SIMSSA researchers and developers also presented.</p>
            <p>Dr. Goto’s Thursday lecture on <a href="http://www.cirmmt.org/activities/distinguished-lectures/goto">“Frontiers of Music technologies: Singing synthesis and active music listening”</a> covered many different aspects of music technology, both in terms of music creation and appreciation. The music creation part included the singing synthesis system <a href="https://staff.aist.go.jp/t.nakano/VocaListener/">VocaListener</a>, the robot singer system <a href="https://staff.aist.go.jp/t.nakano/VocaWatcher/">VocaWatcher</a> (pictured below), and a discussion of the influence of singing synthesis superstar <a href="http://vocaloid.wikia.com/wiki/Hatsune_Miku">Hatsune Miku</a>.</p>
            <p> Screenshot from <a href="https://www.youtube.com/watch?v=wJ5IYs6CATkhttp://">VocaWatcher demonstration on Youtube</a></p>
            <p>On the music appreciation side, we were introduced to <a href="http://songle.jp/">Songle</a>, an active music listening web service, and <a href="http://songrium.jp/">Songrium</a>, oriented towards music browsing.</p>
            <p>The next day, Dr. Goto introduced the CIRMMT...
          </div>
          <br />
          <p>
            <a href="../blog/cirmmt-workshop-on-usability-and-user-experience-for-music-information-systems/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/elvis-database-better-than-ever/">Elvis Database — better than ever.</a></h2>
          <br>
          <p> Posted by ehopkins on September 30, 2015</p>
          <br>
          <div class="post-excerpt">
            <p>A key part of the <a href="http://elvisproject.ca/">ELVIS Project</a> is the <a href="http://database.elvisproject.ca/">ELVIS Database</a>, a crowd-sourced resource of musical scores in symbolic notation (e.g. MEI, MusicXML). The usefulness of the database depends on contributions from all kinds of users, so developing a friendly, functional interface is key. Today’s post features one of our developers in the DDMAL lab discussing some of the big changes he worked on over the summer. Take a look at some of the improvements, and even <a href="http://database.elvisproject.ca/pieces/upload/">try uploading a piece</a>!</p>
            <p>Guest post by Alex Parmentier</p>
            <p>My name is Alex Parmentier. I’m an undergrad in Computer Science at McGill university, and over the last few months I’ve been making big improvements to the <a href="http://database.elvisproject.ca/">ELVIS Database</a> which I’m eager to share.</p>
            <p>The two major features I would like to focus on are the all-new upload and update interface and the improved searching interface.</p>
            <p>When I began working...
          </div>
          <br />
          <p>
            <a href="../blog/elvis-database-better-than-ever/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/new-release-diva-js-4-0/">New Release: Diva.js 4.0 is here!</a></h2>
          <br>
          <p> Posted by ehopkins on September 14, 2015</p>
          <br>
          <div class="post-excerpt">
            <p>Last week, we released Diva.js 4.0 (Document Image Viewer with AJAX), a new version of our open-source document image viewer. <a href="https://github.com/magoni">Evan Magoni</a> is the lead developer on Diva in <a href="https://ddmal.music.mcgill.ca/">our lab here at McGill</a>, and we’re excited to share what he’s been working on. Using Diva on their own websites, libraries, archives, and museums can present high-resolution document page images in a user-friendly interface that has been optimized for speed and flexibility.</p>
            <p><a href="http://ddmal.github.io/diva.js/"></a></p>
            <p>Some highlights of version 4.0 include:</p>
            <p>support for the <a href="http://iiif.io/">International Image Interoperability Framework</a> (IIIF). Supporting this standardized format makes Diva part of the larger movement to enhance and promote sharing of archival image collections.</p>
            <p>“Book Layout” view, presenting document images as openings, or facing pages.</p>
            <p>Several demos are available at <a href="http://ddmal.github.io/diva.js/try/">http://ddmal.github.io/diva.js/try/</a></p>
            <p><a href="http://ddmal.github.io/diva.js/try/iiif-highlight-pages/"></a></p>
            <p>Other improvements include:</p>
            Improved integration with existing web applications, including <a href="http://cantus.simssa.ca/">Cantus Ultimus</a>, the <a href="https://github.com/DDMAL/Rodan">Rodan Client</a> (still a work...
          </div>
          <br />
          <p>
            <a href="../blog/new-release-diva-js-4-0/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/searching-for-latent-structure-in-corpora-with-hierarchical-clustering/">Searching for Latent Structure in Corpora with Hierarchical Clustering</a></h2>
          <br>
          <p> Posted by ehopkins on September 03, 2015</p>
          <br>
          <div class="post-excerpt">
            <p>Guest post from Alex Morgan, PhD student at McGill</p>
            <p>Over the summer we’ve been working to integrate hierarchical clustering into our <a href="http://vis-framework.readthedocs.org/en/vis-framework-2.0.0/">VIS Music Analysis Framework</a> to help us reveal latent structure in musical corpora. Hierarchical clustering is a type of machine learning that groups data sets by how similar they are to one another. In hierarchical clustering, we begin with n groups each containing one data set. In the example below, each starting group is the intervallic profile of a two-voice piece by Josquin, Lassus, or Morley. The two most similar groups are then merged with one another, leaving us with n - 1 groups. This process is repeated until all of the starting singleton groups are merged into one big group. Then, we look at the visual representation of this hierarchical clustering, called a dendrogram, and focus on the intermediary stages of grouping to see if any meaningful...
          </div>
          <br />
          <p>
            <a href="../blog/searching-for-latent-structure-in-corpora-with-hierarchical-clustering/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/simssa-summer-conferences-new-york-and-brussels/">SIMSSA Summer Conferences: New York and Brussels</a></h2>
          <br>
          <p> Posted by ehopkins on August 19, 2015</p>
          <br>
          <div class="post-excerpt">
            <p>SIMSSA has had a busy summer, with many of our team travelling to present on the work we’ve been doing. Highlights include conferences in New York and Brussels, where we were able to give SIMSSA workshops and present on some of our research.</p>
            IAML/IMS in New York
            <p>The <a href="http://www.iaml.info/">International Association of Music Libraries, Archives and Documentation Centres</a> (IAML) and the <a href="http://ims-international.ch/">International Musicological Society</a> (IMS) hosted a congress on <a href="http://www.musiclibraryassoc.org/page/IAML_IMS_2015/">“Music Research in the Digital Age”</a> from 21-26 June 2015. SIMSSA is, of course, all about digital music research, so several of our team members were in attendance to present on and discuss the subject.</p>
            <p>We hosted SIMSSA Workshop VI, well-attended by the group below:</p>
            <p></p>
            <p>There was also a panel on the <a href="http://music-encoding.org/">Music Encoding Initiative</a> (MEI), chaired by Frans Wiering, featuring SIMSSA speakers including Perry Roland, Andrew Hankinson, Ichiro Fujinaga, Laurent Pugin, Johannes Kepler, and Richard Sänger....
          </div>
          <br />
          <p>
            <a href="../blog/simssa-summer-conferences-new-york-and-brussels/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/working-with-jsymbolic-and-elvis/">Working with jSymbolic and ELVIS</a></h2>
          <br>
          <p> Posted by ehopkins on August 06, 2015</p>
          <br>
          <div class="post-excerpt">
            <p>Cory McKay is one of our SIMSSA Co-Investigators, and a professor at Marianapolis College. Along with Tristano Tenaglia, one of our research assistants, he’s been doing some great work with <a href="http://jmir.sourceforge.net/">jSymbolic</a> software and ways of using it with our <a href="http://elvisproject.ca/">ELVIS Project</a> tools. He presented his latest news at a lab meeting the other week and we’re sharing it with you here, too.</p>
            <p>jSymbolic extracts statistical descriptors from symbolic music files. These descriptors include the familiar categories of pitch, melody, texture, rhythm, instrumentation, dynamics, and chords (coming soon!). Currently jSymbolic reads MIDI and MEI files, and saves features as ACE XML (with Weka ARFF and CSV coming soon).</p>
            <p></p>
            <p>These features have some fun applications in terms of machine learning and doing research and analysis with ELVIS — check out Cory’s presentation below for more detail and some neat examples of what we can do.</p>
            <p><a href="../assets/files/jSymbolicELVIS.pdf">PDF</a> and <a...
          </div>
          <br />
          <p>
            <a href="../blog/working-with-jsymbolic-and-elvis/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/profile-of-new-simssa-postdoc-reiner-kraemer/">Profile of new SIMSSA postdoc Reiner Krämer</a></h2>
          <br>
          <p> Posted by sagransj on July 10, 2015</p>
          <br>
          <div class="post-excerpt">
            <p> Reiner in his new office in the McGill music technology suite. Picture taken by Jacob Sagrans, July 9, 2015.</p>
            <p>Yesterday I sat down and chatted with Reiner Krämer, who recently joined the SIMSSA team at McGill as a post-doctoral fellow. Reiner comes to us from the US, where he recently completed a PhD in music theory at the University of North Texas. His dissertation analyzed <a href="https://en.wikipedia.org/wiki/Algorithmic_composition">algorithmic music</a> created through <a href="http://artsites.ucsc.edu/faculty/cope/">David Cope</a>’s artificial intelligence software <a href="http://www.telegraph.co.uk/culture/music/music-news/6404737/Emily-Howell-the-computer-program-that-composes-classical-music.html">Emily Howell</a>. As part of his dissertation research, Reiner investigated the feasibility of using machine learning techniques to analyze music written by a computer. He was excited to learn about the SIMSSA project last year at the annual meeting of the American Musicological Society and the Society for Music Theory—when he saw the announcement for the postdoc opening, he knew he had to apply.</p>
            <p>So far, Reiner has mostly been familiarizing himself...
          </div>
          <br />
          <p>
            <a href="../blog/profile-of-new-simssa-postdoc-reiner-kraemer/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/simssa-student-profiles/">SIMSSA student profiles</a></h2>
          <br>
          <p> Posted by sagransj on June 30, 2015</p>
          <br>
          <div class="post-excerpt">
            <p>I recently visited the McGill music technology labs, meeting many of the students (plus one postdoc) who are working on the SIMSSA project and learning about the work they are doing this summer.</p>
            <p> Post author <a href="http://www.jacob.sagrans.com/">Jacob Sagrans</a> talking with Ian Karp at the <a href="http://ddmal.music.mcgill.ca">Digital Distributed Music Archives and Libraries (DDMAL) lab</a> at McGill University’s <a href="http://www.mcgill.ca/music">Schulich School of Music</a>. Photo taken by Ling-Xiao Yang, June 22, 2015.</p>
            <p> Photo of SIMSSA project members outside the Schulich School of Music in Montreal. From left to right: Alexander Morgan, Ryan Bannon, René Rusch, Ian Karp, Evan Magoni, William Bain, Julie Cumming, Yihong Luo, Jacob Sagrans, Ichiro Fujinaga, Jon Wild, Catherine Motuz, Marina Borsodi-Benson, Andrew Hankinson, Alexandre Parmentier, Tristano Tenaglia, Karen Desmond, Jane Hatter. Photo taken by Darryl Cameron, June 3, 2015.</p>
            <p>Below are brief profiles of everyone I talked to and summaries of the work they are doing. This...
          </div>
          <br />
          <p>
            <a href="../blog/simssa-student-profiles/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/the-fingerprint-algorithm-project/">The “Fingerprint Algorithm” project </a></h2>
          <br>
          <p> Posted by lrisk on March 20, 2015</p>
          <br>
          <div class="post-excerpt">
            <p>Here is a <a href="http://simssa.ca../assets/files/RiskFingerprintAlgorithm2015-03-20.pdf">PDF of the presentation</a> that Lillio Mok and I gave today at the <a href="http://www.cirmmt.org/activities/workshops/research/digital_musicology/digital_musicology">Workshop on Digital Musicology: Revisiting the Collaborative Process Between Music Researchers and Computer Programmers</a>. Thanks to <a href="http://www.cirmmt.org">CIRMMT</a> (Research Axis 2) for hosting the conference and to <a href="http://www.uu.nl/medewerkers/FWiering">Dr. Frans Wiering</a>, the workshop keynote, for his insightful comments. The attached PDF combines our Powerpoint from today with a more detailed presentation that we gave to the ELVIS group a few weeks ago.</p>
            <p>Some background on the project:</p>
            <p>I’m a doctoral candidate in musicology at McGill, and Lillio Mok is an undergraduate student in Computer Science. We started working on this algorithm in summer 2014.</p>
            <p>My dissertation research focuses on traditional music in Quebec, and particularly on some of the musical and cultural shifts that occurred in the late 19th and early 20th centuries and that helped define traditional music (usually called “musique...
          </div>
          <br />
          <p>
            <a href="../blog/the-fingerprint-algorithm-project/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/cirmmt-workshop-on-digital-musicology/">CIRMMT Workshop on digital musicology</a></h2>
          <br>
          <p> Posted by ich on March 20, 2015</p>
          <br>
          <div class="post-excerpt">
            <p>The subtitle of the <a href="http://www.cirmmt.org/activities/workshops/research/digital_musicology/digital_musicology">workshop</a> held today was Revisiting the collaborative process between music researchers and computer programmers. The workshop opened with a remark by CIRMMT Distinguished Lecturer Frans Wiering. Four papers were presented by SIMSSA members: Laura Risk and Lillio Mok, The fingerprint algorithm: Detecting and quantifying similarity in fiddle tunes (see below for more details); Jon Wild and Andie Sigler: Towards automated stylistic fingerprinting of Renaissance polyphony using dissonance-treatment schemata; Alex Morgan, _ Interval succession analysis, dissonance treatment, and transparency in Renaissance treatises and tepertoire_; René Rusch and Ryan Bannon, Music analysis as a workflow? An automated approach to studying voice leading in the Bach chorales.</p>
          </div>
          <br />
          <p>
            <a href="../blog/cirmmt-workshop-on-digital-musicology/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/catherine-motuz-cesr/">Catherine Motuz @CESR </a></h2>
          <br>
          <p> Posted by ich on March 16, 2015</p>
          <br>
          <div class="post-excerpt">
            <p>Catherine Motuz gave a talk entitled: Contrepoint et humanités numériques: L’analyse des models improvisatoires en utilisant “ELVIS” at <a href="http://cesr.univ-tours.fr">CESR (Centre d’Études Supérieures de la Renaissance)</a> in Tours, France.</p>
            <p></p>
          </div>
          <br />
          <p>
            <a href="../blog/catherine-motuz-cesr/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/simssa-tenor-2015/">SIMSSA @TENOR 2015</a></h2>
          <br>
          <p> Posted by ich on March 11, 2015</p>
          <br>
          <div class="post-excerpt">
            <p>Our paper: Single Interface for Music Score Searching and Analysis (I. Fujinaga and A. Hankinson) has been accepted as a poster at the <a href="http://tenor2015.tenor-conference.org">First International Conference on Technologies for Music Notation and Representation (TENOR 2015)</a> (28–30 May 2015, Paris, France).</p>
          </div>
          <br />
          <p>
            <a href="../blog/simssa-tenor-2015/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/barbara-and-three-women/">Barbara and Three Women</a></h2>
          <br>
          <p> Posted by ich on March 10, 2015</p>
          <br>
          <div class="post-excerpt">
            <p>Congratulations to Barbara Swanson, our post-doc, for being awarded a two-year SSHRC Postdoctoral Fellowship at York University with <a href="http://ampd.yorku.ca/about-us/our-faculty/leslie-korrick">Prof. Leslie Korrick</a>. Here’s the title and the project description:</p>
            <p>Painting the Concerto delle donne: Female Vocal Virtuosity in Early Modern Italian Art</p>
            <p>The Concerto delle donne (1580–1597) was the first professional female vocal ensemble, comprised of three virtuosic singers at the court of Ferrara, Italy. Envied by courts across Europe, the Concerto delle donne quickly inspired a craze for female singers and sound. Prestigious courts in Mantua, Florence and Rome established rival ensembles within a few years of the Concerto delle donne’ s debut. No images are known to survive of the three core singers—Laura Peverara, Anna Guarini, and Livia D’Arco. This is despite their riveting vocal virtuosity as described by leading contemporary writers like Torquato Tasso and Giovanni Battista Guarini; their pioneering status as professional women at court, often...
          </div>
          <br />
          <p>
            <a href="../blog/barbara-and-three-women/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/diva-at-duke/">Duke and Diva</a></h2>
          <br>
          <p> Posted by ahankins on February 16, 2015</p>
          <br>
          <div class="post-excerpt">
            <p>We always love hearing how our tools are helping libraries and archives, even if they’re not being used specifically for music analysis. Our <a href="http://ddmal.github.io/diva.js">Diva.js</a> image viewer is one of our flagship projects, and we’re excited to see what the folks at <a href="http://library.duke.edu">Duke University Libraries</a> have been doing with Diva.</p>
            <p>The David M. Rubinstein Rare Book &amp; Manuscript Library has been engaged in a project to digitize their collection of early Greek manuscripts dating from the 9th to 17th centuries. Each book is captured at a <a href="http://blogs.library.duke.edu/bitstreams/2015/02/05/indiana-jones-greek-manuscripts/">very high resolution</a>. They then convert their digitized images to the Pyramid TIFF format, and <a href="http://library.duke.edu/digitalcollections/earlymss/?page=1">present them online</a>. By the end of 2015 they are hoping to have all 106 of their Early Manuscripts Collection digitized and available online.</p>
            <p></p>
            Detail from a <a href="http://library.duke.edu/digitalcollections/earlymss_emsgk01006/">New Testament Gospel</a>, Duke University Digital Collections
            <p>
              Additionally, they have significant documents like a
              <a href="http://library.duke.edu/digitalcollections/rubenstein_hdims01001/">
                manuscript copy...
          </div>
          <br />
          <p>
          <a href="../blog/diva-at-duke/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/simssa-vitrinhn-dhshowcase-2015/">SIMSSA @VitrinHN / DHShowcase 2015 </a></h2>
          <br>
          <p> Posted by ich on February 05, 2015</p>
          <br>
          <div class="post-excerpt">
            <p>Audrey Laplante gave a talk at the <a href="http://figura-concordia.nt2.ca/table-ronde/vitrinehn-dhshowcase-2015">VitrinHN / DHShowcase 2015</a> on 23 January 2015 at Concordia University. The talk was entitled “Introduction to SIMSSA”.</p>
          </div>
          <br />
          <p>
            <a href="../blog/simssa-vitrinhn-dhshowcase-2015/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/nemisig/">SIMSSA at NEMISIG</a></h2>
          <br>
          <p> Posted by ahorwitz on February 04, 2015</p>
          <br>
          <div class="post-excerpt">
            <p>This last weekend, a group of students from McGill attended the 2015 meeting of the Northeast Music Information Special Interest Group (NEMISIG) at Ithaca College and Cornell University in Ithaca, NY. Post-doctoral fellow Andrew Hankinson was there along with graduate students Ling-Xiao Yang and Andrew Horwitz. During the Research Talks section on the first day, Andrew Hankinson gave a talk on SIMSSA, mentioning:</p>
            An overview to the project similar to Ichiro’s introductory talk from the <a href="http://simssa.ca/blog/simssa-workshop-iva">SIMSSA Workshop IV</a> last September The progress on <a href="http://cantus.simssa.ca">Cantus Ultimus</a> Ling-Xiao’s work on <a href="https://github.com/DDMAL/Rodan">Rodan</a> Andrew Horwitz’s work on <a href="http://ddmal.github.io/diva.js/">Diva.JS</a>
            <p>He also gave an overview of the other work happening in the lab, including the <a href="http://cric.music.mcgill.ca/">CRIC</a> robotic harpsichord under construction and Gabriel Vigliensoni’s work on user context in music recommendation systems.</p>
            <p>With all the work that we’ve been putting into music over the last few months, this year’s NEMISIG came with...
          </div>
          <br />
          <p>
            <a href="../blog/nemisig/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/cantus-ultimus-notes-28-1-2015/">Cantus ultimus biweekly meeting-28/1/2015</a></h2>
          <br>
          <p> Posted by jhatter on January 28, 2015</p>
          <br>
          <div class="post-excerpt">
            Salzinnes Exhibit Ideas
            <p>Jennifer’s ideas for the exhibit include:</p>
            having an interface to allow people to interact with the MS (should not be connected to the internet) Andrew recommended setting up a laptop or desktop computer for the MS interface a that display tracks the progress of the music on the page while a recording plays (ambient sound, not in headphones) Andrew says that one of the MA students in the lab is developing software that could be used for this Jennifer will explore the possibility of using the Anon. 4 recording of music from the Salzinnes she will listen to the Anon. 4 recording with the MS, to make sure they followed the versions exactly we will also need to get permission from Anon. 4 and CBC St. Roch, St. Hubert, and Marian selections are possible repertoire Concert and Perhaps Recording from Salzinnes for SIMSSA in Halifax seeking a...
          </div>
          <br />
          <p>
            <a href="../blog/cantus-ultimus-notes-28-1-2015/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/simssa-workshop-iva/">SIMSSA Workshop IV, no. 1</a></h2>
          <br>
          <p> Posted by cmotuz on September 30, 2014</p>
          <br>
          <div class="post-excerpt">
            <p>Yesterday’s CIRMMT Workshop, the fourth to feature the SIMSSA project, kicked off with a summary and update by Ichiro Fujinaga.</p>
            <p>Ichiro opened the session with a summary of all SIMSSA has become so far. It is like “Google scores…minus Google.” (Well ok, a little bit of Google:<a href="http://research.google.com/pubs/author39086.html"> Douglas Eck</a> is on our advisory board.) Its main toolset still revolves around Optical Music Recognition, but it now also offers sophisticated musical querying, in the form of ELVIS.</p>
            <p>The main goal of SIMSSA is to provide access to digitized scores worldwide, from a single website. This involves not only the interlinking of libraries (see our <a href="http://simssa.ca/people">Partners</a> to see which libraries are on board so far), but also finding a wealth of music in books that have already been digitized by Google Books, Hathi Trust or other online resources.</p>
            <p>SIMSSA is redefining what “access” to scores means. Right now, musicians are...
          </div>
          <br />
          <p>
            <a href="../blog/simssa-workshop-iva/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/press-releases-for-the-sshrc-partenership-grant/">Press Releases for the SSHRC Partnership Grant</a></h2>
          <br>
          <p> Posted by ich on August 29, 2014</p>
          <br>
          <div class="post-excerpt">
            <p>Finally, the public announcement of the <a href="http://www.sshrc-crsh.gc.ca/results-resultats/recipients-recipiendaires/2013/partnerships-partenariats-eng.aspx">SSHRC Partnership Grants</a></p>
            <p>Press Release (McGill) in <a href="http://www.mcgill.ca/newsroom/channels/news/mcgill-led-partnership-projects-receive-sshrc-funding-238500" target="\_blank">English</a> or <a href="https://www.mcgill.ca/newsroom/fr/channels/news/un-soutien-du-crsh-pour-des-partenariats-novateurs-238500" target="\_blank">French</a>.Press Release by <a href="http://www.mcgill.ca/music/channels/news/professor-ichiro-fujinaga-and-his-team-researchers-awarded-25-million-dollar-grant-ssh" target="\_blank">Schulich School of Music</a>.</p>
            <p>News Release in <a href="http://publications.mcgill.ca/reporter/2014/09/sshrc-grants-fuel-researchers-to-tune-of-6-8-million/" target="\_blank">McGill Reporter</a>.</p>
          </div>
          <br />
          <p>
            <a href="../blog/press-releases-for-the-sshrc-partenership-grant/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/sonification/">Sonification of Intervals</a></h2>
          <br>
          <p> Posted by Mike Winters on October 01, 2013</p>
          <br>
          <div class="post-excerpt">
            <p>I’ve been working on the ELVIS project for a little bit over a month now. Though I began working with Christopher on the web-interface and back-end, in the past few weeks, I’ve been focused mostly on sonification.</p>
            <p>Sonification, in case you don’t know, is a systematic process in which data is transformed into sound. At the moment, I’ve been listening to the extracted intervals of Dufay, Josquin, Palestrina, and Beethoven at speeds up to 10,000 intervals per second. Though I predicted that sonification could be used to differentiate these corpora, it turns out that it can probably do much more. For the Digging into Data Conference, I’ve generated some recordings in which sonification exposes dramatic changes in the temporal evolution of the data, and helps identify patterns at local and global time scales.</p>
            <p>To give you an idea of what each interval sounds like, imagine a pianist lightly striking the...
          </div>
          <br />
          <p>
            <a href="../blog/sonification/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/introducing-elvis-the-computer-driven-music-analysis-research-project/">Introducing ELVIS, the Computer-Driven Music Analysis Research Project</a></h2>
          <br>
          <p> Posted by Christopher Antila on September 27, 2013</p>
          <br>
          <div class="post-excerpt">
            <p>Summary: I discuss the basic implementation details of a music-analysis computer program I’m helping to write. Our goal is to find musical patterns that will help us describe musical style more precisely. You can visit our (temporary) website at http://elvis.music.mcgill.ca or if you’re reading this in the future and that doesn’t work, you can view our new website at http://elvisproject.ca. You can view our code (AGPLv3+) on GitHub here: https://github.com/ELVIS-project</p>
            <p>One of the most useful things I’ve done over the past couple of years, at least in terms of learning about computers and programming, is to read the blog posts written by members of various free software communities. Is it about software I don’t use? Is it too technical for me? Is it not even about software, but the larger ideas of the community? Is it written in barely-comprehensible English? Doesn’t matter—everything is useful and interesting, and I’m thankful for...
          </div>
          <br />
          <p>
            <a href="../blog/introducing-elvis-the-computer-driven-music-analysis-research-project/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/cirmmt-workshop-september-7th-2013-part-iv-elvis/">CIRMMT Workshop, September 7th, 2013, Part IV: ELVIS</a></h2>
          <br>
          <p> Posted by Catherine Motuz on September 17, 2013</p>
          <br>
          <div class="post-excerpt">
            <p>The afternoon session of the CIRMMT Workshop focused on the ELVIS project, which will continue to be a part of SIMSSA after the Digging into Data challenge officially ends in January, 2014.</p>
            <p>Julie Cumming: Introduction to ELVIS (Electronic Locator of Vertical Interval Sequences)</p>
            <p>Julie began the session with an introduction to what ELVIS is and how it all got started. Ultimately, ELVIS has the same goal as Rodan:to provide an open-source tool set for the online analysis on music, which can be operated not only by computer programmers, but also by musicologists who would not consider themselves to be tech-savvy.</p>
            <p>The idea behind ELVIS dates from a 15th-century music treatise by Johannes Tinctoris, the Liber de arte contrapuncti of 1477. This treatise hashes out the pairs of successive intervals allowed in Renaissance counterpoint, showing not only all possibilities but also judging some better than others. 536 years later, these same...
          </div>
          <br />
          <p>
            <a href="../blog/cirmmt-workshop-september-7th-2013-part-iv-elvis/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/cirmmt-workshop-september-7th-2013-part-iii-music-digitization-in-the-world/">CIRMMT Workshop, September 7th, 2013, Part III: Music Digitization in the World</a></h2>
          <br>
          <p> Posted by Catherine Motuz on September 14, 2013</p>
          <br>
          <div class="post-excerpt">
            <p>Laurent Pugin: Looking at printed music anthologies in the context of digitization</p>
            <p>Laurent Pugin, a former McGill postdoc now working for <a href="http://www.rism-ch.org/">RISM Switzerland</a>, focused on the challenges of using OMR software on large collections of music. Using <a href="http://www.aruspix.net/">Aruspix</a>, a programme that uses machine learning and a graphical user interface (GUI) to perform OMR on early printed music, Laurent has been processing the resources of <a href="http://digirep.rhul.ac.uk/">Early Music Online</a>. This resource, the product of a JISM rapid igitization grant involving the Royal Holloway, British Library and RISM UK, incudes 324 anthologies of printed music from the sixteenth century, or around 10000 pieces. The pieces are rich in metadata but because the images are produced from microfilms, the image quaility is variable.</p>
            <p>The variable quality, along with book formats, notation types and printing methods, reduced the selection of pieces that Aruspix could process. Partbooks and choirbooks were machine-readable, but table...
          </div>
          <br />
          <p>
            <a href="../blog/cirmmt-workshop-september-7th-2013-part-iii-music-digitization-in-the-world/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/cirmmt-workshop-september-7th-2013-part-ii-rodan-and-diva/">CIRMMT Workshop, September 7th, 2013, Part II: Rodan and Diva</a></h2>
          <br>
          <p> Posted by Catherine Motuz on September 13, 2013</p>
          <br>
          <div class="post-excerpt">
            <p>Andrew Hankinson &amp; Ryan Bannon: An introduction to Rodan</p>
            <p>Andrew began the session by outlining the deficiencies of commercially-available optical music recognition software, as these provided the impetus for him to bring the process back to the drawing board. In most cases, OMR is so unreliable that it is faster for an advanced user to enter notation by hand than to correct all the errors made by the system. It is also improssible to improve the system because all the (numerous) processes involved in OMR are carried out in a “black box” process: you see what goes in and what comes out but none of what happens in the middle. It is difficult for two users to carry out work on a single source simultaneously, and each user is limited to the processing power of their desktop computer or laptop. OMR systems don’t learn, which has two implications: first, one...
          </div>
          <br />
          <p>
            <a href="../blog/cirmmt-workshop-september-7th-2013-part-ii-rodan-and-diva/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/cirmmt-workshop-september-7th-2013-part-i-introduction/">CIRMMT Workshop, September 7th, 2013, Part I : Introduction</a></h2>
          <br>
          <p> Posted by Catherine Motuz on September 12, 2013</p>
          <br>
          <div class="post-excerpt">
            <p>Last Saturday, the <a href="http://ddmal.music.mcgill.ca/">DDMAL Lab</a> hosted a workshop outlining the many dimensions of the ever-expanding SIMSSA project. The morning began with prof. Ichiro Fujinaga extending a warm welcome to all participants, stating that this workshop represents the 5th or so in a series, and is being held partially in preparation for an upcoming grant application due October 1st.</p>
            <p>Ichiro Fujinaga: Introduction</p>
            <p>As an introduction to SIMSSA for those new to the project, Ichiro gave his <a href="http://en.wikipedia.org/wiki/Elevator_pitch">elevator pitch</a>: “SIMSSA is Google Scores, minus Google,” going on to clarify that this doesn’t mean that Google will never be involved, but simply that they aren’t as the project presently exists. The many dimensions of SIMSSA involve developing and improving systems for Optical Music Recognition (OMR), learning how to construct sophisticated queries on musical documents, and amassing OMR, musical texts, and search &amp; analysis tools onto a single website. A tangential dimension...
          </div>
          <br />
          <p>
            <a href="../blog/cirmmt-workshop-september-7th-2013-part-i-introduction/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/may-11-hack-day/">May 11 "Hack Day"</a></h2>
          <br>
          <p> Posted by Catherine Motuz on July 07, 2013</p>
          <br>
          <div class="post-excerpt">
            <p>On May 11th, after a successful and well-attended series of talks the afternoon before, the ELVIS team met in the CIRMMT seminar room for a kind of “Hack Day.” This involved getting out our laptops and sitting around the room, each with a set of specific tasks to address that day, alone or in groups, taking advantage of a lively but focused atmosphere and the resources of each others’ presence. For example, having Myke Cuthbert around made it possible to see with certainty which issues in VIS stemmed from the VIS programme itself, and which stemmed from Music21, which runs in conjunction with it, and to fix as many as possible. The presence of both musicologists and programmers in the room made it possible for concerns about music-analysis functionality to be addressed immediately. In some cases, teams were able to consult each other for advice on making queries, such as...
          </div>
          <br />
          <p>
            <a href="../blog/may-11-hack-day/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/may-10-cirmmt-workshop/">May 10 CIRMMT Workshop</a></h2>
          <br>
          <p> Posted by Catherine Motuz on July 07, 2013</p>
          <br>
          <div class="post-excerpt">
            <p>On Friday, May 10th and Saturday, May 11th, the ELVIS team met here at McGill to exchange ideas and to work together on pushing ELVIS forward.</p>
            <p>The session began on Friday with a series of talks by each of the teams to a crowded seminar room, showing what directions they have been following in their research. Julie Cumming, Catherine Motuz and Christopher Antila spoke on behalf of McGill, showing the ELVIS database and especially the VIS software that we have been using to analyze vertical interval successions. The team from Yale, including Chris Whyte (who, replacing his advisor who couldn’t make it for the conference, dubbed himself “the poor man’s Ian Quinn”) and Kirill Zikanov, explained the projects that they are working on. These involved the <a href="http://www.classicalarchives.com/">classical-archives.com</a> database of over four thousand pieces in MIDI format, including Byrd, Vivaldi, and major composers from Bach to Wagner. The main metadata...
          </div>
          <br />
          <p>
            <a href="../blog/may-10-cirmmt-workshop/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/batches-of-data-cmme-and-sikuli/">Batches of Data: CMME and Sikuli</a></h2>
          <br>
          <p> Posted by Catherine Motuz on April 03, 2013</p>
          <br>
          <div class="post-excerpt">
            <p>So far, assembling the ELVIS database has been a manual process, with each file being converted (if necessary), uploaded, and catalogued with metadata by students. (Ichiro calls this method—I presume affectionately—”gradsourcing”.) This is not a bad way to begin: by having to think about every file we put on the site, we now have a good idea of what kind of database we have, what kind of metadata it’s appropriate for us to collect, and problems that might come up with certain filetypes (MIDI files have been an adventure which I will relate in another post!). In order to expand our collection to the one we hoped for, we have to start automating processes. We are exploring how to automate uploading pieces that share the same metadata, and will hopefully have news on this soon. In the meantime, Ryan, a recent addition to our team, has learned a clever way...
          </div>
          <br />
          <p>
            <a href="../blog/batches-of-data-cmme-and-sikuli/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/queries/">Queries!</a></h2>
          <br>
          <p> Posted by Catherine Motuz on December 10, 2012</p>
          <br>
          <div class="post-excerpt">
            <p>Christmas has arrived early. With a good selection of pieces in the ELVIS database and the VIS/music21 interface up and running, it is time to come up with queries to run.</p>
            <p>One of the main goals of music theory and musicology since they began has been to try to pin down what gives a composer their personal style. Palestrina and Bach sound different even if they are both writing for a 4-part choir, as do Palestrina and Josquin (to slightly specialized ears), but where exactly do the differences lie? After all, these composers all follow many of the same contrapuntal rules, avoiding parallel 5ths and using many of the same formulations to start and end phrases. One of the main type of queries will be to see if analyzing the interaction of melodic and vertical intervals might provide musical fingerprints for composers. We will start with the above-named three because...
          </div>
          <br />
          <p>
            <a href="../blog/queries/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/elvis-at-the-ams/">ELVIS at the AMS!</a></h2>
          <br>
          <p> Posted by Catherine Motuz on November 14, 2012</p>
          <br>
          <div class="post-excerpt">
            <p>Seven members of McGill’s ELVIS team have just returned from New Orleans, where ELVIS was presented alongside the SIMSSA project at the <a href="http://www.ams-net.org/neworleans/">AMS/SMT conference</a>. On November 1st, in a joint AMS/SMT session entitled “New Digital Projects for the Study and Dissemination of Medieval and Renaissance Music,” a panel discussion where Julie Cumming presented ELVIS and also delivered a paper on collaborative research in digital humanities. The members of the panel as well as some of the discussions which ensued can be found <a href="https://sites.google.com/a/haverford.edu/ams_digitalearlymusic/the-panel">here</a> as well as in the program book, available for download on the <a href="http://www.ams-net.org/neworleans/">AMS site</a>. The crowd of around seventy scholars was very enthusiastic, and we are especially touched by Susan Boynton’s (Columbia University) public appreciation of both the Liber and Salzinnes projects as she described their usefulness as pedagogic tools.</p>
            <p>That evening, the ELVIS members from different universities took advantage of being in the...
          </div>
          <br />
          <p>
            <a href="../blog/elvis-at-the-ams/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/everyone-needs-a-nate-silver/">Everyone needs a Nate Silver</a></h2>
          <br>
          <p> Posted by Catherine Motuz on November 07, 2012</p>
          <br>
          <div class="post-excerpt">
            <p>As Nate Silver wowed the world last week with his statistical prowess, proving triumphantly that for all the value we place on our gut instincts, they don’t compare with mathematics when it comes to, say, predicting election results. Keeping this in mind, as the first strings of numbers pour out of VIS, our current task is learning how to interpret them. Following Ichiro Fujinaga’s maxim “Never reinvent the wheel,” the ELVIS team is happy to have among us Jamie Klassen, a BA student in mathematics and statistics, as well as Alex Morgan, a music theory graduate student with math proficiency, and Prof. Jon Wild, who did his bachelor degrees at McGill in both music and physics.</p>
            <p>The numbers produced by VIS queries are called <a href="http://en.wikipedia.org/wiki/N-gram">n-grams</a>, with N representing the number of successive vertical intervals represented. The most basic n-gram in ELVIS is the 2-gram, made up of two successive...
          </div>
          <br />
          <p>
            <a href="../blog/everyone-needs-a-nate-silver/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/introducing-vis/">Introducing "VIS"</a></h2>
          <br>
          <p> Posted by Catherine Motuz on September 17, 2012</p>
          <br>
          <div class="post-excerpt">
            <p>In a collaborative project between musicologists and computer programmers, there is a decision to be made about who learns what. Should programmers learn enough about music that they can translate the questions of musicologists into code, or should musicologists and theorists learn how to use analytic software such as music21 (which involves some basic programming skills) in order to ask their own questions? The time commitment is enormous on both sides.</p>
            <p>Even Humdrum, whose music encoding notation is so intuitive that it is possible to sing or play directly from it, starts to look technical when it comes to asking questions. For instance, this is how one would search a piece for French 6th chords:</p>
            solfa file extract -i ‘**solfa’ ditto grep ‘6-.*4+’ grep 2
            <p>The advantage to this system is that one can ask basically anything, but the disadvantage is that it requires a 40-chapter handbook. Some of us...
          </div>
          <br />
          <p>
            <a href="../blog/introducing-vis/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/building-a-corpus/">Building a Corpus</a></h2>
          <br>
          <p> Posted by Catherine Motuz on September 03, 2012</p>
          <br>
          <div class="post-excerpt">
            <p>A necessary requirement for any kind of corpus research is, obviously, a corpus. It is one thing to have access to libraries of the last thousand years of music, but quite another to have it in a format readable by a machine. Constructing the ELVIS corpus is not complete, but as the time approaches to run queries, it seems like an excellent moment to thank some of the people who have contributed the notation files that make it up. Some of the files provided come from public sites, such as cpdl.org (known as the “Choral Wikipedia), and others have been donated by other research projects and even individuals. Files are uploaded individually in order to make sure that a minimum amount of metadata is attached to each entry. Because of the time this takes (1-2 minutes per entry in general), not all donated pieces are up on the database yet....
          </div>
          <br />
          <p>
            <a href="../blog/building-a-corpus/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/rockstars-among-us/">Rockstars among us</a></h2>
          <br>
          <p> Posted by Catherine Motuz on August 28, 2012</p>
          <br>
          <div class="post-excerpt">
            <p>There has been a lot of coming and going in the lab over the summer months, people heading off in all directions for their weeks off. Some visiting family, some taking a holiday, and one touring the Americas with their highly successful rock band. That would be Gabriel. Gabriel is the Ph.D. student in the lab responsible for making OMR work: He does the nitty gritty of turning black-and-white images into sources of information. His screen is constantly filled with staff-finders and note shape processors which he writes, tests, and tweaks, unassumingly and patiently developing some of the most cutting-edge technology in the world.</p>
            <p>But this year, Gabriel has been whisked away by his band of a former life, <a href="http://www.lucybell.com/">Lucybell</a>, onto a reunion tour that marks their foundation at the Universidad de Chile 21 years ago. He has already played to packed houses all over Chile, and will be...
          </div>
          <br />
          <p>
            <a href="../blog/rockstars-among-us/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/simssa-workshop-overview-july-28th-2012/">SIMSSA workshop overview, July 28th 2012</a></h2>
          <br>
          <p> Posted by cmotuz on August 06, 2012</p>
          <br>
          <div class="post-excerpt">
            <p>Yesterday morning a few dozen librarians attending the <a href="http://www.iaml.info/">IAML</a> conference in Montreal attended a <a href="http://www.cirmmt.org/activities/workshops/research/simssa/event">CIRMMT workshop exhibiting SIMSSA</a>. Ichiro opened the presentation with an overview of what SIMSSA is and reminding the specialized audience that the project needs librarians on board in order to become a true “partnership” project and receive maximum funding.</p>
            <p><a href="https://ccrma.stanford.edu/~esf/">Eleanor Selfridge-Field</a> gave a stunning keynote presentation called “Between an Analog Past and a Digital Future.” Her talk gave a whirlwind tour of the exciting state of <a href="http://en.wikipedia.org/wiki/List_of_Online_Digital_Musical_Document_Libraries">digital music collections</a> today, the issues surrounding them and the many possible paths for the future. She showed us images of recovered music and watermarks from faded documents, discussed projects using optical recognition systems for differentiating the handwriting of scribes, and of course talked through the very practical implications for musicologists of not having to travel halfway across the world to see sources. “I’m wondering,” she...
          </div>
          <br />
          <p>
            <a href="../blog/simssa-workshop-overview-july-28th-2012/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/categories-vs-tags/">Categories vs. Tags</a></h2>
          <br>
          <p> Posted by Catherine Motuz on July 06, 2012</p>
          <br>
          <div class="post-excerpt">
            <p>The ELVIS project is booming, with over 4000 entries. Composers with over 100 entries include Chopin, Handel, Haydn, Obrecht, Palestrina, Scarlatti, Schubert, and Bach, with more than 1000 pieces or movements.</p>
            <p>At first we met regularly to discuss the best ways to organize our information, learning that in the field of information science, computers are changing the way we have to think about our data. Previously, we would put it into categories such as those provided by the <a href="http://www.loc.gov/catdir/cpso/lcco/">Library of Congress</a>, but now that keyword searches are so prevalent and the field of corpus linguistics is blossoming, so tagging data is gaining headway. The downside to tagging is that you have to know what you are looking for so that you can type it into the search box. Meanwhile, categories offer easy browsing, but the problem with categories is that there has to be the right pre-defined category to...
          </div>
          <br />
          <p>
            <a href="../blog/categories-vs-tags/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/personal-update-for-catherine/">Personal Update for Catherine</a></h2>
          <br>
          <p> Posted by Catherine Motuz on July 05, 2012</p>
          <br>
          <div class="post-excerpt">
            <p>The last few months have been hectic, and ironically a lot of my computer time has gone to inputting music into Finale, because OMR is in such an early stage that it’s still faster to manually input pieces, not only when working off of a dirty facsimile, as I so often do, but even when working from scores made in Finale in the first place. So I’ve edited about 45 pieces in the last month - at least they will go into the ELVIS database. The rest of the time, I’ve got to know a few of the ins and outs of Drupal, and have been managing the ELVIS website (both the technical side and helping to establish rules and vocabularies) as well as contributing to it. To practise installing a module without worrying about side-effects, I put in a tag cloud so that we can see the most common...
          </div>
          <br />
          <p>
            <a href="../blog/personal-update-for-catherine/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/rodan-server-infrastructure/">Rodan server infrastructure</a></h2>
          <br>
          <p> Posted by Alastair Porter on July 04, 2012</p>
          <br>
          <div class="post-excerpt">
            <p>As part of the Simssa project we have been developing Rodan, a software application for helping people to convert images of music into a searchable symbolic format. A main aspect of the Rodan project that I have been working is the integration of the software and supporting infrastructure. Rodan is a complex tool, with six different pieces of software working together in the background to perform the recongition process.</p>
            <p>The main server application is written using the <a href="https://djangoproject.com/">Django</a> web framework. We use the <a href="http://www.postgresql.org/">PostgreSQL</a> database server to store all data generated by the application. We use a python library called <a href="http://www.celeryproject.org/">celery</a> to perform long-running operations like music recognition. This helps us to keep the interactive webpage responsive. The main site sends a message to celery that requests an action to be performed on an image by adding the message to a queue, run by <a href="http://www.rabbitmq.com/">RabbitMQ</a>. An...
          </div>
          <br />
          <p>
            <a href="../blog/rodan-server-infrastructure/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/on-developing-the-frontend-and-other-components-of-rodan/">On developing the frontend and other components of Rodan</a></h2>
          <br>
          <p> Posted by Wendy Liu on July 04, 2012</p>
          <br>
          <div class="post-excerpt">
            <p>In the last month or so I’ve been working primarily on designing the frontend for Rodan, as well as working on certain components of the backend. On the frontend side, I’ve been doing most of the templating/stylesheets/javascript for the interface of Rodan, except when it comes to the Javascript image processing modules (binarisation, despeckling, segmentation, rotation, and cropping - see Blog entry: JavaScript Image Processing Modules for Rodan). On the backend side of things, I worked on: creating a framework for easily creating tasks, the project/workflow management functionality, and a system for restarting and checking timing information for tasks, as well as miscellaneous bug fixes and feature additions in other areas. I also worked on integrating <a href="http://ddmal.music.mcgill.ca/diva">Diva.js</a> into Rodan, and added the search highlighting features.</p>
          </div>
          <br />
          <p>
            <a href="../blog/on-developing-the-frontend-and-other-components-of-rodan/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/javascript-image-processing-modules-for-rodan/">JavaScript Image Processing Modules for Rodan</a></h2>
          <br>
          <p> Posted by Brian Stern on July 03, 2012</p>
          <br>
          <div class="post-excerpt">
            <p>This post will present a suite of JavaScript-based image processing modules, designed to operate on scaled-down versions or full-size portions of high-resolution music score images. These modules include binarisation, rotation, cropping, segmentation (for staff removal), and despeckling. For the Rodan project, it is essential to enable the users to correct the automated image processing algorithms in real-time, on the client-side. This is not possible with full-size images, as their high resolution causes long program execution times, but the scaled or partial images can provide useful previews for how an algorithm will run on the original file. When the user has finished adjusting the preview, the parameters of the operation they have performed (angle of rotation, binarisation threshold, etc.) are sent to a server-side program to run on the full image.</p>
          </div>
          <br />
          <p>
            <a href="../blog/javascript-image-processing-modules-for-rodan/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/neon-js-updates/">Neon.js Updates</a></h2>
          <br>
          <p> Posted by Gregory Burlet on June 19, 2012</p>
          <br>
          <div class="post-excerpt">
            <p>Over the past few weeks I’ve added some new functionality and goodies to the Neon.js neume notation editor. Ornamentation: dots can now be toggled on puncta (neumes with one note). Clefs: shift clefs vertically on the staff, insert new clefs anywhere on the staff, delete clefs, and update the shape of a clef. Divisions: insert all four types of divisions, delete divisions, and move divisions. Custos: are tied to the first note on the next staff. The next tasks on the burner are handling more ornamentation: draw, insert, update, and delete episemata as well as drawing more complex neume structures in the editor.</p>
            <p>You can see a demo of Neon.js in action here.</p>
            <p>Also, the Neon.js paper was accepted to ISMIR 2012! See you in Porto!</p>
          </div>
          <br />
          <p>
            <a href="../blog/neon-js-updates/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/news-update/">News Update</a></h2>
          <br>
          <p> Posted by cmotuz on March 19, 2012</p>
          <br>
          <div class="post-excerpt">
            <p>First of all, the whole lab congratulates Dr. John Ashley Burgoyne, who has now officially received his Ph.D. title. Ashley is getting ready to move to the Netherlands in June to start a Post-Doctoral position at the University of Amsterdam to study what makes tunes stick in our ears. We also congratulate Remi Chiu, the senior musicologist on the SIMSSA project, who will head into his thesis defence next week having just accepted a position for next academic year at Loyola University in Baltimore, Maryland. Bravo to both and all the best with future endeavours. The lab also bid a fond farewell to Mathieu Bergeron this week, who just finished his post-doctoral position with us and will stay in Montreal and continue to work on his own projects.</p>
            <p>The lab is abuzz with preparing paper proposals for the ISMIR 2012 conference, to be held in Porto this October. Jason has...
          </div>
          <br />
          <p>
            <a href="../blog/news-update/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/putting-drupal-to-good-use/">Putting Drupal to good use</a></h2>
          <br>
          <p> Posted by cmotuz on March 12, 2012</p>
          <br>
          <div class="post-excerpt">
            <p>The ELVIS project is in full swing, after a very short ramp up. Our team of Research Assistants has been collecting public domain music notation files and uploading them into what will be a vast database of music spanning from 1300-1900. McGill will focus on collecting early music, that is, up until 1700 or so, while researchers at other Universities will focus on later repertoire.</p>
            <p>What allowed us to get going so quickly with making our data website is a content management platform called <a href="https://www.drupal.org/">Drupal</a>. In a world where hundreds of different versions of essentially the same software are written to give users this bell but not that whistle, or worse yet, where companies use software that come with all the bells and whistles possible, using only a small percentage of its capability while the massive program weighs down the whole operating system.</p>
            <p>Needless to say Drupal is different....
          </div>
          <br />
          <p>
            <a href="../blog/putting-drupal-to-good-use/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/elvis-and-ra3-host-a-mini-conference/">ELVIS and RA3 host a mini-conference</a></h2>
          <br>
          <p> Posted by cmotuz on March 05, 2012</p>
          <br>
          <div class="post-excerpt">
            <p>As spring has coyly come and harshly vanished again, the ELVIS project has started to show its first shoots. Right before the start of Reading Week, around 40 students and researchers assembled for a <a href="http://www.cirmmt.org/activities/workshops/research/musical-info/event">mini-conference</a> hosted by <a href="http://www.cirmmt.org/research/axes/Musical_Information_Retrieval">CIRMMT’s Research Axis 3 (RA3)</a>. Specialists in Music Information Retrieval (MIR) congregated in Montreal to share their ideas and projects on Thursday and Friday February 16th and 17th, while Saturday morning was devoted to the ELVIS project.</p>
            <p>The event began with a talk by <a href="http://www.lis.illinois.edu/people/faculty/jdownie">J. Stephen Downie</a> as part of CIRMMT’s <a href="http://www.cirmmt.org/activities/distinguished-lectures">Distinguished Lecture Series</a>. His talk ranged from the broad question of whether MIR is part of science or part of musicology, to the nitty gritty details of adapting speech recognition technology to detect musical features. He also addressed one of the major criticisms by musicologists of technology - that the results of computer-operated queries (whether audio feature recognition...
          </div>
          <br />
          <p>
            <a href="../blog/elvis-and-ra3-host-a-mini-conference/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/neon/">Neon</a></h2>
          <br>
          <p> Posted by cmotuz on February 27, 2012</p>
          <br>
          <div class="post-excerpt">
            <p> Thanks to the tireless efforts of <a href="http://www.music.mcgill.ca/~greg/">Gregory Burlet</a>, SIMSSA has a new web application! It’s called the Neume Editor ONline (NEON), and it’s making a splash. Right now, NEON renders <a href="http://music-encoding.org/home">mei</a> files of square-note notation into graphic form. In the above example from the demo, you can see how the application has rendered our file of the Salve Regina from the <a href="http://ddmal.music.mcgill.ca/research/omr/Search_the_Liber_Usualis">Liber Usualis</a> into the neume shapes and pitches specified by the code. The shapes are modelled on those in the <a href="http://www.klemm-music.de/makemusic/finale/index.php">Finale medieval plug-in</a>, to which Greg has added dots and is working on adding the more unusual shapes from the Liber Usualis.</p>
            <p>But rendering is not all! The main goal of this application is to make it work backwards too. If you go to the demo and click on a neume, you’ll see that you can drag it around. Eventually, these edits will alter...
          </div>
          <br />
          <p>
            <a href="../blog/neon/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/nine-million-sources/">Nine Million Sources</a></h2>
          <br>
          <p> Posted by cmotuz on February 09, 2012</p>
          <br>
          <div class="post-excerpt">
            <p>In my last post I mentioned that I estimated that there were around nine million different sources of printed music in the world. How did I come up with that number?</p>
            <p>Most of my information comes from <a href="http://www.rism.info/">RISM</a>, the international organization which works with over 7000 libraries worldwide to try to document all of the written and printed music in the world, from Anthems and Allemandes to Zajal and Zarzuela. The RISM website makes its own estimate of the number of music prints in the world, with the usual disclaimer that even they, the world’s collectors of music, can only attempt to hit somewhere in the ballpark. RISM reckons:</p>
            <p>about 1.8 million music manuscripts between 1600 and 1800</p>
            <p>at least 2 million music manuscripts between 1800 and 1950</p>
            <p>around 140 000 printed music books before 1800</p>
            <p>around 4 million printed music books after 1800</p>
            <p>This gives us a total...
          </div>
          <br />
          <p>
            <a href="../blog/nine-million-sources/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/who-s-in-the-ivory-tower-now/">Who's in the Ivory Tower Now?</a></h2>
          <br>
          <p> Posted by cmotuz on January 23, 2012</p>
          <br>
          <div class="post-excerpt">
            <p>It’s been very interesting this past week to compare and contrast all the excitement about <a href="http://en.wikipedia.org/wiki/Stop_Online_Piracy_Act">SOPA</a>/<a href="http://en.wikipedia.org/wiki/PROTECT_IP_Act">PIPA</a> with the world of Academia. Traditionally it’s been universities who have been accused of holing up in the ivory tower, but by stark contrast to corporations who benefit from the commercialization of information (to the point of <a href="http://www.futureofcopyright.com/home/blog-post/2011/12/21/american-sentenced-to-one-year-in-prison-for-uploading-x-men-movie.html">imprisoning people for uploading copyrighted material</a>), those of us publicly funded for high-quality research—whatever fruits may bring—are now keen to send all the ideas we come up with into the world as soon as they might be of use to anybody at all.</p>
            <p>That’s why it’s important to have competitions around like the <a href="http://diggingintodata.org/">Digging into Data</a> challenge, and why I’m especially pleased to report that the <a href="http://publications.mcgill.ca/reporter/2012/01/schulich-school-of-music-scholars-among-winners-of-digging-into-data-challenge/">ELVIS project</a>, an international team of researchers led by our own <a href="http://www.mcgill.ca/music/about-us/bio/julie-e-cumming">Julie Cumming</a>, has won one of the prizes on offer. As is usual when...
          </div>
          <br />
          <p>
            <a href="../blog/who-s-in-the-ivory-tower-now/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/spinning-wheels/">Spinning Wheels</a></h2>
          <br>
          <p> Posted by cmotuz on January 20, 2012</p>
          <br>
          <div class="post-excerpt">
            <p>So far, the SIMSSA project has focused on developing OMR search systems and testing them on relatively small documents. Even the very large Liber Usualis, with its 2340 pages, however, is very small when compared to an entire collection of digitized music scores. <a href="http://www.imslp.org/">IMSLP</a> has 157,490 scores and counting, and many libraries from around the world are joining the trend of digitizing their collections. Based on the RISM catalogue and logical extensions, I would estimate there to be around 9 million scores in existence, ranging from 1-1000 pages each, for a total of 100-200 million pages. As our ultimate goal is to be able to do such large scale searches, we have spent some time in the past weeks to considering the problems of processing power that these are going to pose.</p>
            <p>Most of us are used to search times measured in hundredths of a second—Google just showed me...
          </div>
          <br />
          <p>
            <a href="../blog/spinning-wheels/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/happy-new-year/">Happy New Year</a></h2>
          <br>
          <p> Posted by cmotuz on January 11, 2012</p>
          <br>
          <div class="post-excerpt">
            <p>Happy New Year!</p>
            <p>It’s been a lot of fun coming to grips with OMR and discovering for myself how brilliant ideas get put together to develop a cutting edge piece of technology. There’s no denying it though, every so often we hear:</p>
            <p>“That’s all very clever. What’s it for?”</p>
            <p>My job as musicologist on the team is to make sure that not only does the answer to this question guide our research (not to mention our user interfaces), but to try to see the applications of new developments the moment they enter the horizon of technical possibility. That’s why Remi and I sat down with a pen and paper and asked “If computers can learn to read music and analyze it directly from scores, how can this help musicologists / theorists and performers?” Here are some of the things we came up with:</p>
            <p></p>
            <p>The most obvious application is in...
          </div>
          <br />
          <p>
            <a href="../blog/happy-new-year/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/streamlining-gamera/">Streamlining Gamera</a></h2>
          <br>
          <p> Posted by cmotuz on November 30, 2011</p>
          <br>
          <div class="post-excerpt">
            <p>The <a href="http://salzinnes.simssa.ca/">Salzinnes</a> project has gone public! I’m writing from Austria now, here to play in some concerts, yet I got the news right away in the form of a Facebook notification. But of course.</p>
            <p>After feeding the first 60 or so pages of Salzinnes into the computer’s OMR system, <a href="http://gamera.informatik.hsnr.de/">Gamera</a>, we decided it was time to see how efficiently it was actually learning. Gamera learns by making a library of images or “glyphs,” then recognizing new ones by comparing them to its library. It doesn’t just recognize images by their shape and size - after all, sizes can vary drastically depending on the resolution of an image - but by looking at elements such as how symmetrical they are, their black-to-white pixel ratio, and by the patters produced by their pixels when piled onto the x or y axis.</p>
            <p>Here you can see that clivis and a podatus...
          </div>
          <br />
          <p>
            <a href="../blog/streamlining-gamera/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/social-coding/">Social Coding</a></h2>
          <br>
          <p> Posted by cmotuz on November 17, 2011</p>
          <br>
          <div class="post-excerpt">
            <p>Last week the Salzinnes project made its first public appearance in a series of presentations at the AMS Conference in San Francisco. The responses have been encouraging, ranging from appreciation of the <a href="http://ddmal.github.io/diva.js/">diva</a> interface as a tool for working with manuscripts to offers to help us get connected with other libraries and collections to provide us with other sources that we might incorporate into the project.</p>
            <p>Last week the lab was in a flurry of activity getting the demo ready, working out bugs and making it more pleasing to the eye. How it all came together made me wonder how five programmers can coordinate to get a piece of code up and functioning. There’s already a bit of banter across the lab floor, but with complex files, the need to concentrate in a relatively quiet lab, and busy schedules where some things wind up being done on weekends or...
          </div>
          <br />
          <p>
            <a href="../blog/social-coding/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/finding-the-staff-lines-position-in-the-salzinnes-antiphonal/">Finding the staff lines position in the Salzinnes Antiphonal</a></h2>
          <br>
          <p> Posted by gvigliensoni on November 10, 2011</p>
          <br>
          <div class="post-excerpt">
            <p>working in the creation of fully-searchable manuscripts and music documents. For extracting the pitches from within these documents we need to extract the position of the glyphs in the page as well as the position of the staff. The only staff finder algorithm that considers non-parallel staff lines is the Miyao algorithm. Although it works very good in most cases, with our last manuscript, the Salzinnes Antiphonal, I have had some problems with this algorithm.</p>
            <p>The following image shows the staff lines being recognized by the Miyao processing. It can be seen that the algorithm does a good work in the recognized points, i.e., the points and staff lines are properly localized, but there are big portions of the staff lines that are not recognized at all. On top of that, there are overlapped zones of staffs, like in the second staff where the green and light blue zones coincide....
          </div>
          <br />
          <p>
            <a href="../blog/finding-the-staff-lines-position-in-the-salzinnes-antiphonal/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/a-few-words-about-our-resident-diva/">A few words about our resident DIVA</a></h2>
          <br>
          <p> Posted by cmotuz on November 07, 2011</p>
          <br>
          <div class="post-excerpt">
            <p>The premise of DIVA is that it’s a user-friendly interface that allows the browsing of high-resolution, multi-page documents. High quality images take a long time to download on an HTML website, so normally image quality is sacrificed to allow each image to be loaded before the site is browsable. For a book like Salzinnes with over 400 pages, even low-quality images would take a long time, so until now the usual strategy has been to present the book on different pages as thumbnails, with each image expandable (making browing very time consuming indeed), or to force the user to download a bulky .pdf in order to browse the whole book at once. DIVA is different: it’s optimized to load only what is in the viewing window at any given moment, making it possible to browse through high quality images with minimal load time and no need to download a file....
          </div>
          <br />
          <p>
            <a href="../blog/a-few-words-about-our-resident-diva/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/gearing-up-to-show-simssa-to-the-world/">Gearing up to show SIMSSA to the world</a></h2>
          <br>
          <p> Posted by cmotuz on November 04, 2011</p>
          <br>
          <div class="post-excerpt">
            <p>It’s been a busy week here in the lab as we all prepare for the presentation of the SIMSSA project at the <a href="http://www.ams-net.org/sanfrancisco/">AMS Conference</a> next week.</p>
            <p>Our .tiff files have arrived and Remi and Laura have been back in <a href="http://gamera.informatik.hsnr.de/">gamera</a>, once again teaching the computer to distinguish between a podatus and a c-clef, a custos and a punctum inclinatum, and pitches in general from the random specs of dirt and discolouration on each page of music. I had a go on the program too at last, only to find myself proceeding at a snail’s pace in comparison to the other two. When I complained, Laura came in and showed me a myriad tricks and shortcuts she had found to speed things up, in particular how to tell the computer to approve the classification of many instances of the same object at once instead of sorting through one by...
          </div>
          <br />
          <p>
            <a href="../blog/gearing-up-to-show-simssa-to-the-world/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/libmei-released/">LibMEI Released</a></h2>
          <br>
          <p> Posted by ahankins on October 25, 2011</p>
          <br>
          <div class="post-excerpt">
            <p>As part of our ongoing development of tools necessary to support the OMR of musical materials, we are launching the first beta version of <a href="http://ddmal.music.mcgill.ca/libmei">LibMEI</a>, a C++ application library that supports the reading and writing of MEI music notation files.</p>
            <p>This launch is timed to coincide with a talk given at the 2011 International Society of Music Information Retrieval (ISMIR) conference in Miami, FL. This talk, titled <a href="http://ismir2011.ismir.net/papers/OS3-1.pdf">“The Music Encoding Initiative as a document-encoding framework”</a> describes how MEI can be used to rapidly develop support for new notation encoding systems.</p>
            <p>The <a href="http://ddmal.music.mcgill.ca/libmei">LibMEI website</a> has more information about this software, including how to get and use software, documentation, and an issue tracker.</p>
          </div>
          <br />
          <p>
            <a href="../blog/libmei-released/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/yes-we-cantus/">YES we CANTUS!</a></h2>
          <br>
          <p> Posted by cmotuz on October 18, 2011</p>
          <br>
          <div class="post-excerpt">
            <p>This past week, while we wait for our .tiffs to be ready for OMR, we’ve been combing and parsing the plethora of information available in the <a href="http://cantusdatabase.org/">CANTUS</a> database. And what a fantastic resource it is! For each Latin ecclesiastical chant in each manuscript, CANTUS gives a page of information. The information for the first chant set to music in <a href="http://salzinnes.simssa.ca/">Salzinnes</a>, for instance, looks like this: </p>
            <p>As the first two letters of SIMSSA stand for “Single Interface,” we’d like to make this information available on the same system as the searchable images of the Salzinnes antiphonal. As space is not an issue, we’d also like to automatically expand the abbreviations to their full names without having to refer to the legend, so I’ve been getting my head around reading the above, especially the liturgical use information, thanks to the legends provided on the CANTUS website. The feast, Dom....
          </div>
          <br />
          <p>
            <a href="../blog/yes-we-cantus/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/the-road-to-recognition-preparing-the-images/">The Road to Recognition: Preparing the Images</a></h2>
          <br>
          <p> Posted by ahankins on October 13, 2011</p>
          <br>
          <div class="post-excerpt">
            <p>We’ve been working on getting our new book, the <a href="http://salzinnes.simssa.ca/">Salzinnes Antiphonal</a>, prepped and ready for the OMR process. Part of this process involves separating the different components of the images into different files, minimizing clutter and reducing the amount of information that the computer will have to work with.</p>
            <p>We start with a fairly handsome page. Meet Salzinnes f. 9r:</p>
            <p></p>
            <p>The first thing we need to do is to convert this image to black-and-white through a process called “binarization.” This process makes it very easy for a computer to decide what parts of the image are important and what aren’t. If it’s a black pixel, the computer needs to do something about it; if it’s a white pixel, it can ignore it. The binarization process cleans up some of the <a href="http://en.wikipedia.org/wiki/Foxing">foxing</a>, page creases, and other bits of the image that the computer might otherwise eventually confuse with...
          </div>
          <br />
          <p>
            <a href="../blog/the-road-to-recognition-preparing-the-images/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/jpegs-vs-tiffs-and-browsing-the-cantus-database/">JPEGs vs TIFFs and browsing the Cantus Database</a></h2>
          <br>
          <p> Posted by cmotuz on October 11, 2011</p>
          <br>
          <div class="post-excerpt">
            <p>First of all, a hearty congratulations to SIMSSA’s Wendy Liu and lab-partner Saining Li for their <a href="http://www.mcgilldaily.com/2011/10/coding-coffee-and-concrete-innovation/">good citizenship award at the Montreal Hackathon</a>, for improving their wikinotes.ca site to make note sharing more accessible to students.</p>
            <p>The question of the week is: How does the quality of an image affect a computer’s success at Optical Music Recognition (OMR)? Most of the images of music put up on the Internet are in the forms .jpeg or .pdfs that began their existence as .jpeg files. The problem with .jpeg is that it involves “lossy compression,” or compression by discarding bits of data. Jpegs are clever because they discard data that the eye tends not to notice at a distance or in web viewing, but when we try to manipulate the file or blow it up to many times its size, this loss of data becomes apparent: little halos appear around notes...
          </div>
          <br />
          <p>
            <a href="../blog/jpegs-vs-tiffs-and-browsing-the-cantus-database/">Read more</a>
          </p>
          <hr>
          <br>
          <h2><a href="../blog/welcome-to-the-new-simssa-blog/">Welcome to the New SIMSSA Blog!</a></h2>
          <br>
          <p> Posted by cmotuz on September 30, 2011</p>
          <br>
          <div class="post-excerpt">
            <p>Welcome to the new blog for the project “Single Interface for Music Score Searching and Analysis” (SIMSSA). Here you can learn about the ins and outs of this cutting-edge project, which involves developing Optical Music Recognition (OMR) to allow computers read music of many different notational styles, making digital scores searchable. Just as when you scan a text, a computer will use Optical Character Recognition (OCR) to convert graphics into letters, OMR converts notated music into a form where it can be separated out into its components and analyzed. You can already browse the results of last year’s project, where the <a href="http://liber.simssa.ca/">lab taught a computer how to read the Liber Usualis</a>.</p>
            <p>Now our exciting piece of news is that we’ve received and put online a digital copy of the <a href="http://salzinnes.simssa.ca/">Salzinnes Antiphonal</a>. This is the manuscript which we’ll use for the next step of our project: teaching a computer...
          </div>
          <br />
          <p>
            <a href="../blog/welcome-to-the-new-simssa-blog/">Read more</a>
          </p>
          <hr>
          <br>      <br>
        </div>
      </div>
    </div>
    <script>
      $(document).ready(function(){
        $('.icon_rotation').on({
          'click': function () {
            var origsrc = $(this).attr('src');
            var src = '';
            if (origsrc == '../assets/0-expand_off.png') src = '../assets/0-expand_on.png';
            if (origsrc == '../assets/0-expand_on.png') src = '../assets/0-expand_off.png';
            $(this).attr('src', src);
          }
        });
      });
    </script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
    <script type="text/javascript" src="../js/bootstrap.min.js"></script>
  </body>
</html>
<!DOCTYPE html>
<html lang="en-us">  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
  <meta name="theme-color" content="#3E3F3A">
  <!-- Windows Phone -->
  <meta name="msapplication-navbutton-color" content="#3E3F3A">
  <!-- iOS Safari -->
  <meta name="apple-mobile-web-app-status-bar-style" content="#3E3F3A">
  <title>      An Interview with Johanna Devaney &middot; SIMSSA  </title>  <link rel="shortcut icon" type="image/ico" href="../../assets/favicon.png">  <!-- CSS -->
  <link rel="stylesheet" href="../../assets/css/main.css" />  <!-- <link rel="stylesheet" type="text/css" href="http://localhost:4000/css/bootstrap.css">
  <link rel="stylesheet" type="text/css" href="http://localhost:4000/css/simssa.css"> -->
</head>  <body id ="Site" class='layout-reverse theme-base-sm sidebar-overlay'>    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"><div class="navbar navbar-expand-sm navbar-default navbar-fixed-top" role="navigation">
        <div class="container" id="nav-container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="">SIMSSA</a>
            </div>
            <div class="collapse navbar-collapse">
                <ul class="navbar-nav nav mr-auto">
<!--                     <li class="active"><a href="/">Home</a></li> -->                    <li><a href="../../about">About</a></li>
                    <li><a href="../../people">Participants</a></li>
                    <!-- <li><a href="/publications">Publications</a></li> -->                    <li class="dropdown">
                      <a class="dropdown-toggle" role="button" data-toggle="dropdown" href="#">Activities<span class="caret"></span></a>
                      <ul class="dropdown-menu" role="menu">                            <li><a href='../../activities/corpora-and-datasets/' target='_top' >Datasets and Corpora</a></li>                            <li><a href='../../activities/impact/' target='_top' >Our impact</a></li>                            <li><a href='../../activities/media/' target='_top' >Media</a></li>                            <li><a href='../../activities/presentations/' target='_top' >Presentations</a></li>                            <li><a href='../../activities/publications/' target='_top' >Publications</a></li>                            <li><a href='../../activities/workshops/' target='_top' >Workshops</a></li>                      </ul>
                    </li>                    <li class="dropdown">
                      <a class="dropdown-toggle" role="button" data-toggle="dropdown" href="#">Projects and links<span class="caret"></span></a>
                      <ul class="dropdown-menu" role="menu">                            <li><a href='http://cantus.simssa.ca/' target='_top' >Cantus Ultimus</a></li>                            <li><a href='' target='_top' >ELVIS Project</a></li>                            <li><a href='http://jmir.sourceforge.net/index_jSymbolic.html' target='_top' >jSymbolic2</a></li>                            <li><a href='http://liber.simssa.ca' target='_top' >Liber Usualis</a></li>                            <li><a href='https://github.com/DDMAL/Andrew-Hughes-Chant' target='_top' >LMLO</a></li>                            <li><a href='' target='_top' >Musiclibs</a></li>                            <li><a href='http://ddmal.teamwork.com/' target='_top' >Teamwork</a></li>                        <hr id="menu-divider">
                        <li><a href="http://github.com/DDMAL" target="_blank">Github</a></li>
                        <li><a href="http://twitter.com/simssaproject" target="_blank">Twitter</a></li>
                      </ul>
                    </li>                    <li><a href="../../blog">Blog</a></li>
                    <li><a href="../../opportunities">Opportunities</a></li>                    <li><a href="../../contact">Contact us</a></li>                </ul>
            </div>
        </div>
    </div>        <div class="post">
  <div class="container">
    <div class="page-header" id="banner">
        <div class="row">
            <div class="col-lg-12">
            </div>
        </div>
    </div>
    <div class="row">
        <div class="col-lg-12">
        	<h2>An Interview with Johanna Devaney</h2><br />
        	<p class="blog-post">
        	   Posted by ehopkins on April 12, 2018
          </p><br />
			    <p><p><em><a href="http://www.devaney.ca">Johanna Devaney</a> is Assistant Professor of Music Theory and Cognition at <a href="https://music.osu.edu/people/devaney.12">Ohio State University</a>, currently teaching in the <a href="https://steinhardt.nyu.edu/music/technology">music technology program at NYU</a>, and the newest SIMSSA Collaborator. We had a chance to talk over Skype about music and the digital humanities, learning to program, and the ways that music research can drive technological advances even beyond disciplinary bounds.</em></p><p><img src="../../assets/img/devaney_sm.png" alt="" /></p><p><strong>EH:</strong> Thank you so much for agreeing to talk with me today. We’re pretty excited to have you on board as a SIMSSA collaborator. Since music information retrieval as I’ve experienced it attracts folks with a lot of different disciplinary interests, I’m always curious about the paths people have taken to end up here. I looked at your CV and it looks like you started out playing piano and oboe and doing some composing, and then you did a BFA in music and history, and then a computer programming diploma, all before ever getting into Music Information Retrieval specifically. Can you tell me a little bit more about that early education and how you got into computer programming?</p><p><strong>JD:</strong> I’d always been interested in using computers. I’m old enough that when I got my first computer the way that you got new games was either coding them or downloading them from bulletin board systems. I’d always found computers really interesting but I didn’t actually pursue that through my undergraduate. When I graduated with my BFA, I wanted to learn more about programming, so I decided to do the computer programming diploma. A year into the diploma, I started a Master’s at York in Composition, and worked on both simultaneously for a year. Initially, I was focused on applying programming in my compositions. This expanded to research due to interest in in my composing for vocalists and unfretted string instruments capable of flexible intonation. I wanted my performance instructions to extend what they were doing, as opposed to just prescribe something completely different. During the course of my Master’s, I realized that there was very little written about this, so I thought, well, this would be an interesting subject for a PhD. This ultimately led me to <a href="http://ddmal.music.mcgill.ca/">Ich’s lab</a> at McGill.</p><p><strong>EH:</strong> How did your time at McGill influence work you’ve done since then, going on in MIR?</p><p><strong>JD:</strong> The great thing about the <a href="http://www.mcgill.ca/music/home">Schulich School of Music</a> at McGill is opportunity to engage with both the technical and the musicological. In addition to working with Ich, I worked closely with <a href="http://www.mcgill.ca/music/jonathan-wild">Jon Wild</a> and <a href="http://www.mcgill.ca/music/peter-schubert">Peter Schubert</a> on all of the singing voice work that I was doing. Also <a href="https://www.cirmmt.org/">CIRMMT</a> provided many other opportunities to intersect with people doing thing. This was really valuable not only for learning how to do interdisciplinary research, but also learning how to talk to people from different disciplines.</p><p><strong>EH:</strong> A lot of what we do at SIMSSA involves symbolic representations of digitized scores, and I know a lot of what you do involves symbolic representations of performance. Could you talk a little bit about making computational models of performance — what is your interest in that, and what sorts of problems do you see that applying to?</p><p><strong>JD:</strong> In terms of western art music scholarship, there’s a bias towards notated music. But in terms of what people experience, its the performance. Many of questions that we may be asking of the notated music, such as musical structure, can being linked to the listener experience. Thus, it’s useful to be able to examine performances and to see whether the things we find through symbolic analysis are being emphasized by the performer or not. You can have some theories by looking at the score, you can augment those by seeing how people perform it, and you can put those two together in terms of building your reading of the piece.</p><p><strong>EH:</strong> I know you’re usually at Ohio State and you mentioned you’re at New York University this year. What projects have you been working on and what sorts of things are going on at NYU?</p><p><strong>JD:</strong> So I usually am in a music theory and cognition program, but I’ve been teaching in the music technology program here this year. I’ve been intersecting with both people doing music cognition — mainly a lot of stuff on emotion and film music actually, I’ve been advising students on that — and people doing music information retrieval. I’ve been continuing some of the work I’ve been doing with my <a href="http://gettavern.org">TAVERN dataset</a> a bit, as well as issues around encoding performance data.</p><p><strong>EH:</strong> <a href="http://gettavern.org">TAVERN</a> is how I think I first heard about you, but can you give a brief idea of how that project started?</p><p><strong>JD:</strong> Yeah, so, it originally came about because I managed to convince Google that this was an interesting thing to fund through their Google Faculty Research Award program.</p><p><strong>EH:</strong> Well done!</p><p><strong>JD:</strong> Yeah! The grand vision is to develop a model of symbolic music analysis where you’d be parsing the structurally significant notes from the entire musical surface. The first step in developing this develop was to to get some labelled data. I thought that theme and variations form was a really useful way to do this, because, when there’s consistency in terms of the harmony, you can see how the same harmony is being realized with different textures in a way that is totally ecologically valid. So because I was at OSU in music theory, what I actually had available in my graduate students (aka <a href="https://simssa.ca/blog/introducing-Nat">Nat</a> and <a href="https://simssa.ca/blog/introducing-claire-arthur">Claire</a>!) was expertise in doing music analysis, so I used money in order to do the data set creation, which was really a huge undertaking. The next thing is to think about doing an audio version of it.</p><p><strong>EH:</strong> I wanted to ask you a little about <a href="http://ampact.tumblr.com/">AMPACT</a> since you did that workshop at the Digital Humanities Week in New York recently. Tell me a little bit about the development of AMPACT and the workshop and future plans for it.</p><p><a href="http://ampact.tumblr.com/"><img src="../../assets/img/ampactLOGO.png" alt="" /></a></p><p><strong>JD:</strong> <a href="http://ampact.tumblr.com/">AMPACT</a> uses scored-guided  techniques to extract timing, tuning, dynamics and tempo from recordings of musical performances. <a href="http://ampact.tumblr.com/">AMPACT</a> really came out of my dissertation — it was the tools that I was using to do the analysis of the vocal performances. The name came out of a solid hour-long meeting with Ich, going through all the possible acronyms. I got funding from the NEH Digital Humanities program and that allowed me to do some additional development, specifically to develop the technology to not just do monophonic performances but polyphonic performances as well. The music performance encoding project also fell under that so that’s how I got funding for that too.</p><p><strong>EH:</strong> What sorts of people are coming to your workshop to learn about AMPACT?</p><p><strong>JD:</strong> Since it was the digital humanities event, it was less music scholars and more people who are interested in ethnography of music, but not ethnomusicologists by trade. As well people who are interested in looking at cultural products other than text.</p><p><em>Shown below is a schematic representing the AMPACT process. See <a href="http://ampact.tumblr.com/documentation">here</a> for more.</em></p><p><img src="../../assets/img/ampactSchematic.png" alt="" /></p><p><strong>EH:</strong> The <a href="https://www.frontiersin.org/journals/digital-humanities#">Frontiers in Digital Humanities journal</a>— you’re currently the Specialty Chief Editor for the <a href="https://www.frontiersin.org/journals/digital-humanities/sections/digital-musicology#">Digital Musicology</a> section. Can you tell me a little bit more about that publication, what sorts of work you do and what its goals are?</p><p><strong>JD:</strong> What I’m most interested in is having a space where it’s not just people using tools that have been developed to do — to answer musicological questions — but rather see the way that musicological questions can actually push the development of tools. And not just MIR tools but actually core algorithm development in fields like machine learning or signal processing.</p><p><strong>EH:</strong> What have you worked on with machine learning?</p><p><strong>JD:</strong> I’ve mostly been using classic machine learning approaches as opposed to deep learning techniques, just because the data that I have to work with is relatively small. I’ve worked on classification with support vector machines and music alignment using temporal models like hidden Markov models, and then currently doing some stuff with conditional random fields for the symbolic music analysis from <a href="http://gettavern.org">TAVERN</a>.</p><p><strong>EH:</strong> In terms of learning the technical side of this, how much of your programming knowledge came from your computer programming diploma versus how much have you learned on the job? A lot of musicologists I see learning to code on the job because of getting interested in MIR.</p><p><strong>JD:</strong> In terms of my actual coding I really learned how to code, like actually properly code, when working on my diploma, and what I’ve been learning since has been stuff like the machine learning and signal processing. I feel like it would be really difficult for me to have gotten a handle on programming paradigms like object-oriented programming on the fly.</p><p><strong>EH:</strong> Thanks a lot for talking to me today! I appreciate it, I’m glad we have you on board.</p><p>Learn more about Johanna at <a href="http://devaney.ca">www.devaney.ca</a> or follow her on Twitter <a href="https://twitter.com/jcdevaney">@jcdevaney</a>.</p>
</p>
        </div>
    </div>
    <br /><hr /><br />
    <div class="related">
      <h2>Related Posts</h2>
      <ul class="related-posts">          <li>
            <h3>
              <a href="../../blog/MMLworkshop/">
                Music and Machine Learning Workshop
                <!-- <small>22 Dec 2021</small> -->
              </a>
            </h3>
          </li>          <li>
            <h3>
              <a href="../../blog/ismir2019/">
                ISMIR 2019: Delft
                <!-- <small>16 Dec 2019</small> -->
              </a>
            </h3>
          </li>          <li>
            <h3>
              <a href="../../blog/simssa-xix/">
                SIMSSA XIX: Introducing DACT and MML16
                <!-- <small>11 Dec 2019</small> -->
              </a>
            </h3>
          </li>      </ul>
      <br /><br /><br>
    </div>
  </div>
</div>    <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
    <script type="text/javascript" src="../../js/bootstrap.min.js"></script>
  </body>
</html>
